<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Raivo Koot | Haiping Lu</title><link>https://haipinglu.github.io/authors/raivo-koot/</link><atom:link href="https://haipinglu.github.io/authors/raivo-koot/index.xml" rel="self" type="application/rss+xml"/><description>Raivo Koot</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>Â© 2023 by Haiping Lu</copyright><lastBuildDate>Fri, 31 Dec 2021 00:00:00 +0000</lastBuildDate><image><url>https://haipinglu.github.io/authors/raivo-koot/avatar_hu368ba8047baca63be9535c5458333d04_13841_270x270_fill_q75_lanczos_center.jpg</url><title>Raivo Koot</title><link>https://haipinglu.github.io/authors/raivo-koot/</link></image><item><title>PyKale: an ML Library in PyTorch Ecosystem</title><link>https://haipinglu.github.io/project/pykale/</link><pubDate>Fri, 31 Dec 2021 00:00:00 +0000</pubDate><guid>https://haipinglu.github.io/project/pykale/</guid><description>&lt;p>PyKale is a library in the PyTorch ecosystem aiming to make machine learning more accessible to interdisciplinary research by bridging gaps between data, software, and end users. Both machine learning experts and end users can do better research with our accessible, scalable, and sustainable design, guided by green machine learning principles. PyKale has a unified pipeline-based API and focuses on multimodal learning and transfer learning for graphs, images, texts, and videos at the moment, with supporting models on deep learning and dimensionality reduction.&lt;/p>
&lt;p>PyKale enforces standardization and minimalism, via green machine learning concepts of reducing repetitions and redundancy, reusing existing resources, and recycling learning models across areas. PyKale will enable and accelerate interdisciplinary, knowledge-aware machine learning research for graphs, images, texts, and videos in applications including bioinformatics, graph analysis, image/video recognition, and medical imaging, with an overarching theme of leveraging knowledge from multiple sources for accurate and interpretable prediction.&lt;/p></description></item><item><title>Evaluating transformers for lightweight action recognition</title><link>https://haipinglu.github.io/publication/koot-2021-evaluating/</link><pubDate>Mon, 01 Nov 2021 00:00:00 +0000</pubDate><guid>https://haipinglu.github.io/publication/koot-2021-evaluating/</guid><description/></item><item><title>VideoLightFormer: Lightweight action recognition using transformers</title><link>https://haipinglu.github.io/publication/koot-2021-videolightformer/</link><pubDate>Thu, 01 Jul 2021 00:00:00 +0000</pubDate><guid>https://haipinglu.github.io/publication/koot-2021-videolightformer/</guid><description/></item></channel></rss>