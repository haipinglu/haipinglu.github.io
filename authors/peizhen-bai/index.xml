<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Peizhen Bai | Haiping Lu</title><link>https://haipinglu.github.io/authors/peizhen-bai/</link><atom:link href="https://haipinglu.github.io/authors/peizhen-bai/index.xml" rel="self" type="application/rss+xml"/><description>Peizhen Bai</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© 2025 by Haiping Lu</copyright><lastBuildDate>Mon, 16 Jun 2025 00:00:00 +0000</lastBuildDate><image><url>https://haipinglu.github.io/authors/peizhen-bai/avatar_hue5160dd751d3cb9e2360567f4f150639_28219_270x270_fill_q75_lanczos_center.jpg</url><title>Peizhen Bai</title><link>https://haipinglu.github.io/authors/peizhen-bai/</link></image><item><title>Inverse protein folding via denoising diffusion</title><link>https://haipinglu.github.io/project/inverse-protein-folding/</link><pubDate>Mon, 16 Jun 2025 00:00:00 +0000</pubDate><guid>https://haipinglu.github.io/project/inverse-protein-folding/</guid><description>&lt;p>Inverse protein folding generates valid amino acid sequences that can fold into a desired protein structure, with recent deep-learning advances showing significant potential and competitive performance. However, challenges remain in predicting highly uncertain regions, such as those with loops and disorders. To tackle such low-confidence residue prediction, we propose a &lt;strong>Ma&lt;/strong>sk &lt;strong>p&lt;/strong>rior-guided denoising &lt;strong>Diff&lt;/strong>usion (&lt;strong>MapDiff&lt;/strong>) framework that accurately captures both structural and residue interactions for inverse protein folding. MapDiff is a discrete diffusion probabilistic model that iteratively generates amino acid sequences with reduced noise, conditioned on a given protein backbone. To incorporate structural and residue interactions, we develop a graph-based denoising network with a mask prior pre-training strategy. Moreover, in the generative process, we combine the denoising diffusion implicit model with Monte-Carlo dropout to improve uncertainty estimation. Evaluation on four challenging sequence design benchmarks shows that MapDiff significantly outperforms state-of-the-art methods. Furthermore, the in-silico sequences generated by MapDiff closely resemble the physico-chemical and structural characteristics of native proteins across different protein families and architectures.&lt;/p></description></item><item><title>Molecular property prediction via line graph transformer</title><link>https://haipinglu.github.io/project/molecular-property-prediction/</link><pubDate>Fri, 01 Sep 2023 00:00:00 +0000</pubDate><guid>https://haipinglu.github.io/project/molecular-property-prediction/</guid><description>&lt;p>Molecular property prediction with deep learning has gained much attention over the past years. Owing to the scarcity of labeled molecules, there has been growing interest in self-supervised learning methods that learn generalizable molecular representations from unlabeled data. Molecules are typically treated as 2D topological graphs in modeling, but it has been discovered that their 3D geometry is of great importance in determining molecular functionalities. In this paper, we propose the Geometry-aware line graph transformer (Galformer) pre-training, a novel self-supervised learning framework that aims to enhance molecular representation learning with 2D and 3D modalities. Specifically, we first design a dual-modality line graph transformer backbone to encode the topological and geometric information of a molecule. The designed backbone incorporates effective structural encodings to capture graph structures from both modalities. Then we devise two complementary pre-training tasks at the inter and intra-modality levels. These tasks provide properly supervised information and extract discriminative 2D and 3D knowledge from unlabeled molecules. Finally, we evaluate Galformer against six state-of-the-art baselines on twelve property prediction benchmarks via downstream fine-tuning. Experimental results show that Galformer consistently outperforms all baselines on both classification and regression tasks, demonstrating its effectiveness.&lt;/p></description></item><item><title>Drug–target interaction prediction via bilinear attention network</title><link>https://haipinglu.github.io/project/drug-target-interaction-prediction/</link><pubDate>Wed, 01 Feb 2023 00:00:00 +0000</pubDate><guid>https://haipinglu.github.io/project/drug-target-interaction-prediction/</guid><description>&lt;p>Predicting drug–target interaction is key for drug discovery. Recent deep learning-based methods show promising performance, but two challenges remain: how to explicitly model and learn local interactions between drugs and targets for better prediction and interpretation and how to optimize generalization performance of predictions on novel drug–target pairs. Here, we present &lt;strong>DrugBAN&lt;/strong>, a deep &lt;strong>B&lt;/strong>ilinear &lt;strong>A&lt;/strong>ttention &lt;strong>N&lt;/strong>etwork (&lt;strong>BAN&lt;/strong>) framework with domain adaptation to explicitly learn pairwise local interactions between drugs and targets, and adapt in response to out-of-distribution data. DrugBAN works on drug molecular graphs and target protein sequences to perform prediction, with conditional domain adversarial learning to align learned interaction representations across different distributions for better generalization on novel drug–target pairs. Experiments on three benchmark datasets under both in-domain and cross-domain settings show that DrugBAN achieves the best overall performance against five state-of-the-art baseline models. Moreover, visualizing the learned bilinear attention map provides interpretable insights from prediction results.&lt;/p></description></item><item><title>PyKale: open-source multimodal learning software library</title><link>https://haipinglu.github.io/project/pykale/</link><pubDate>Mon, 17 Oct 2022 00:00:00 +0000</pubDate><guid>https://haipinglu.github.io/project/pykale/</guid><description>&lt;p>PyKale is a library in the PyTorch ecosystem aiming to make machine learning more accessible to interdisciplinary research by bridging gaps between data, software, and end users. Both machine learning experts and end users can do better research with our accessible, scalable, and sustainable design, guided by green machine learning principles. PyKale has a unified pipeline-based API and focuses on multimodal learning and transfer learning for graphs, images, texts, and videos at the moment, with supporting models on deep learning and dimensionality reduction.&lt;/p>
&lt;p>PyKale enforces standardization and minimalism, via green machine learning concepts of reducing repetitions and redundancy, reusing existing resources, and recycling learning models across areas. PyKale will enable and accelerate interdisciplinary, knowledge-aware machine learning research for graphs, images, texts, and videos in applications including bioinformatics, graph analysis, image/video recognition, and medical imaging, with an overarching theme of leveraging knowledge from multiple sources for accurate and interpretable prediction.&lt;/p></description></item><item><title>Low-Bias Evaluation of Drug-Target Interaction</title><link>https://haipinglu.github.io/project-removed/dti-graph-eval/</link><pubDate>Sat, 11 Dec 2021 00:00:00 +0000</pubDate><guid>https://haipinglu.github.io/project-removed/dti-graph-eval/</guid><description>&lt;p>This project is in collaboration with AstraZeneca.&lt;/p>
&lt;p>Drug-target interaction (DTI) prediction is important in drug discovery and chemogenomics studies. Machine learning, particularly deep learning, has advanced this area significantly over the past few years. However, a significant gap between the performance reported in academic papers and that in practical drug discovery settings, e.g. the random-split-based evaluation strategy tends to be too optimistic in estimating the prediction performance in real-world settings. Such performance gap is largely due to hidden data bias in experimental datasets and inappropriate data split.&lt;/p>
&lt;p>In this project, we construct a low-bias DTI dataset and study more challenging data split strategies to improve performance evaluation for real-world settings. Specifically, we study the data bias in a popular DTI dataset, BindingDB, and re-evaluate the prediction performance of three state-of-the-art deep learning models using five different data split strategies: random split, cold drug split, scaffold split, and two hierarchical-clustering-based splits. In addition, we comprehensively examine six performance metrics. Our experimental results confirm the overoptimism of the popular random split and show that hierarchical-clustering-based splits are far more challenging and can provide potentially more useful assessment of model generalizability in real-world DTI prediction settings.&lt;/p></description></item><item><title>Hierarchical clustering split for low-bias evaluation of drug-target interaction prediction</title><link>https://haipinglu.github.io/publication/bai-2021-hierarchical/</link><pubDate>Thu, 02 Dec 2021 00:00:00 +0000</pubDate><guid>https://haipinglu.github.io/publication/bai-2021-hierarchical/</guid><description/></item><item><title>PyKale: Knowledge-aware machine learning from multiple sources in python</title><link>https://haipinglu.github.io/publication/lu-2021-pykale/</link><pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate><guid>https://haipinglu.github.io/publication/lu-2021-pykale/</guid><description/></item><item><title>GripNet: Graph information propagation on supergraph for heterogeneous graphs</title><link>https://haipinglu.github.io/publication/xu-2020-gripnet/</link><pubDate>Thu, 01 Oct 2020 00:00:00 +0000</pubDate><guid>https://haipinglu.github.io/publication/xu-2020-gripnet/</guid><description/></item><item><title>Joint interaction with context operation for collaborative filtering</title><link>https://haipinglu.github.io/publication/bai-2019-joint/</link><pubDate>Thu, 01 Aug 2019 00:00:00 +0000</pubDate><guid>https://haipinglu.github.io/publication/bai-2019-joint/</guid><description/></item></channel></rss>