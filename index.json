[{"authors":["filip-miljkovic"],"categories":null,"content":"We started collaboration with Filip since 2021. We work on the development of (graph) machine learning algorithms for drug discovery and drug repurposing that can lead to real-world impact. See his LinkedIn page for more information.\n","date":1733788800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1733788800,"objectID":"e8869d49862ca0f2fffe59ddc4b735cc","permalink":"https://haipinglu.github.io/authors/filip-miljkovic/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/filip-miljkovic/","section":"authors","summary":"We started collaboration with Filip since 2021. We work on the development of (graph) machine learning algorithms for drug discovery and drug repurposing that can lead to real-world impact. See his LinkedIn page for more information.","tags":null,"title":"Filip Miljkoviƒá","type":"authors"},{"authors":["haiping-lu"],"categories":null,"content":"üèõÔ∏è I am a Professor of Machine Learning at the School of Computer Science and the Head of AI Research Engineering at the Centre for Machine Intelligence, University of Sheffield. I am also the Director of the UK Open Multimodal AI Network (UKOMAIN), funded by EPSRC, building on the Meta-learning for Multimodal Data interest group at the Alan Turing Institute. Follow our UKOMAIN LinkedIn page for the latest updates and opportunities.\nüñ•Ô∏è My research focuses on translational multimodal AI technologies for healthcare and scientific discovery:\n Multimodal AI: Foundation models, generative AI, domain adaptation, and transfer learning. Healthcare: Brain/cardiac imaging, and cancer diagnosis/treatment. Scientific Discovery: Protein engineering, and drug/materials discovery.  I lead the development of the open-source software library PyKale, part of the PyTorch ecosystem, enabling accessible machine learning for interdisciplinary research.\nüèÖ I serve as an Associate Editor of IEEE Transactions on Neural Networks and Learning Systems and IEEE Transactions on Cognitive and Developmental Systems. My awards include a Turing Network Development Award, an Amazon Research Award, and joint Wellcome Trust Innovator and NIHR AI in Health and Care awards.\nüìò Three of my MSc dissertation students have won the Fretwell-Downing Prize for the best MSc Dissertation: Peizhen Bai (2017), Hao Xu (2019), and Mohammod N. I. Suvon (2022). Learn more about the whereabouts of my past team members.\n üì© PhD enquiries: Email me ONE PDF including your CV, a statement on why and your source of funding, 1-3 papers, and transcripts before applying. Also check the English language requirements.\n","date":1733788800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1733788800,"objectID":"ab777c901708e58297c4b8065861f567","permalink":"https://haipinglu.github.io/authors/haiping-lu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/haiping-lu/","section":"authors","summary":"üèõÔ∏è I am a Professor of Machine Learning at the School of Computer Science and the Head of AI Research Engineering at the Centre for Machine Intelligence, University of Sheffield. I am also the Director of the UK Open Multimodal AI Network (UKOMAIN), funded by EPSRC, building on the Meta-learning for Multimodal Data interest group at the Alan Turing Institute.","tags":null,"title":"Haiping Lu","type":"authors"},{"authors":["peizhen-bai"],"categories":null,"content":"Peizhen started his PhD in January 2021 and submitted his PhD dissertation \u0026ldquo;Transferable Representation Learning for Drug Discovery\u0026rdquo; in December 2024. He did his MSc dissertation on context-aware recommender systems with Haiping and was Haiping\u0026rsquo;s first student winning the best dissertation award in the department. He works on graph representation learning models for real-world drug discovery, in collaboration with an AstraZeneca team led by Bino John. See his LinkedIn page for more information.\n","date":1733788800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1733788800,"objectID":"a0ab6f3c08b7e7b70373ac133376da59","permalink":"https://haipinglu.github.io/authors/peizhen-bai/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/peizhen-bai/","section":"authors","summary":"Peizhen started his PhD in January 2021 and submitted his PhD dissertation \u0026ldquo;Transferable Representation Learning for Drug Discovery\u0026rdquo; in December 2024. He did his MSc dissertation on context-aware recommender systems with Haiping and was Haiping\u0026rsquo;s first student winning the best dissertation award in the department.","tags":null,"title":"Peizhen Bai","type":"authors"},{"authors":["xianyuan-liu"],"categories":null,"content":"Xianyuan is the Assistant Head of AI Research Engineering and Senior AI Research Engineer since September 2023. He received his PhD degree in Signal and Information Processing from the University of Chinese Academy of Sciences, China, in 2023. Prior to that, he received his Bachelor‚Äôs degree in Measuring Control Technology and Instruments from Southeast University, China, in 2016. He was a visiting PhD student in our group supported by CSC from September 2019 to September 2021. See his homepage and LinkedIn for more information.\n","date":1733788800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1733788800,"objectID":"8acea76f97d85ada6a9d70f0a9d1c54c","permalink":"https://haipinglu.github.io/authors/xianyuan-liu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/xianyuan-liu/","section":"authors","summary":"Xianyuan is the Assistant Head of AI Research Engineering and Senior AI Research Engineer since September 2023. He received his PhD degree in Signal and Information Processing from the University of Chinese Academy of Sciences, China, in 2023.","tags":null,"title":"Xianyuan Liu","type":"authors"},{"authors":["andrew-swift"],"categories":null,"content":"The collaboration with Andy started in 2017. We develop translational AI technologies with interpretable machine learning for the diagnosis, prognosis, and treatment assessment of cardiovascular diseases. See his profile page for more information.\n","date":1727913600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1727913600,"objectID":"64f18b4817c89b6b8a652e4303d67216","permalink":"https://haipinglu.github.io/authors/andrew-swift/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/andrew-swift/","section":"authors","summary":"The collaboration with Andy started in 2017. We develop translational AI technologies with interpretable machine learning for the diagnosis, prognosis, and treatment assessment of cardiovascular diseases. See his profile page for more information.","tags":null,"title":"Andrew Swift","type":"authors"},{"authors":["chen-chen"],"categories":null,"content":"The collaboration with Chen started in November 2023 when she started her new position at Sheffield. She obtained her MSc and PhD degree from Imperial College London. See her homepage for more information.\n","date":1727913600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1727913600,"objectID":"9172eaf349d6da57a2c668e2a2573ad5","permalink":"https://haipinglu.github.io/authors/chen-chen/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/chen-chen/","section":"authors","summary":"The collaboration with Chen started in November 2023 when she started her new position at Sheffield. She obtained her MSc and PhD degree from Imperial College London. See her homepage for more information.","tags":null,"title":"Chen Chen","type":"authors"},{"authors":["mohammod-suvon"],"categories":null,"content":"Mohammod joined us as an AI Research Engineer (AIRE) in October 2023 and he is also pursuing his PhD in our group. He received his Master\u0026rsquo;s degree in Computer Science with Speech and Language Processing from the University of Sheffield in 2022. Prior to that, he received Bachelor‚Äôs degree in Computer Science and Engineering from North South University, Bangladesh, in 2020. See his LinkedIn page for more information.\n","date":1727913600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1727913600,"objectID":"5f64c51798678951ee9649c4a14284b5","permalink":"https://haipinglu.github.io/authors/mohammod-suvon/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/mohammod-suvon/","section":"authors","summary":"Mohammod joined us as an AI Research Engineer (AIRE) in October 2023 and he is also pursuing his PhD in our group. He received his Master\u0026rsquo;s degree in Computer Science with Speech and Language Processing from the University of Sheffield in 2022.","tags":null,"title":"Mohammod Suvon","type":"authors"},{"authors":["prasun-tripathi"],"categories":null,"content":"Prasun commenced his role as a Visiting Researcher of our group in February 2024. Prior to this, he served as a Postdoctoral Research Associate and a Senior AI Research Engineer in our group from July 2022 to January 2024. He worked on a Wellcome Trust project for the diagnosis, prognosis, and treatment assessment of cardiovascular diseases from cardiac MRI.\nHe received his Ph.D. degree in Computer Science from Indian Institute of Technology, Dhanbad, in 2022. See his LinkedIn page for more information.\n","date":1727913600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1727913600,"objectID":"61f26c892a7a09ff18dd94961c9c3483","permalink":"https://haipinglu.github.io/authors/prasun-tripathi/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/prasun-tripathi/","section":"authors","summary":"Prasun commenced his role as a Visiting Researcher of our group in February 2024. Prior to this, he served as a Postdoctoral Research Associate and a Senior AI Research Engineer in our group from July 2022 to January 2024.","tags":null,"title":"Prasun Tripathi","type":"authors"},{"authors":["shuo-zhou"],"categories":null,"content":"Shuo is now a Lecturer in Machine Learning in our school. He was a PhD student under the supervision of Haiping from March 2018 to Feb 2022. He did his MSc on domain adaptation for brain fMRI classification with Haiping in 2016/17. His research focuses on domain adaptation for medical image analysis, particularly domain-independence maximisation for multisource domain adaptation. See his homepage for more information.\n","date":1727913600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1727913600,"objectID":"4772d675c00b2f31aaf8cb577204167c","permalink":"https://haipinglu.github.io/authors/shuo-zhou/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/shuo-zhou/","section":"authors","summary":"Shuo is now a Lecturer in Machine Learning in our school. He was a PhD student under the supervision of Haiping from March 2018 to Feb 2022. He did his MSc on domain adaptation for brain fMRI classification with Haiping in 2016/17.","tags":null,"title":"Shuo Zhou","type":"authors"},{"authors":["venet-osmani"],"categories":null,"content":"The collaboration with Venet started in July 2023 on an AI Research Engineering project \u0026ldquo;Multimodal Cardiothoracic Disease Prediction\u0026rdquo;. See his homepage for more information.\n","date":1727913600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1727913600,"objectID":"cc34c4ca5b381e387b7ef2d0341fa779","permalink":"https://haipinglu.github.io/authors/venet-osmani/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/venet-osmani/","section":"authors","summary":"The collaboration with Venet started in July 2023 on an AI Research Engineering project \u0026ldquo;Multimodal Cardiothoracic Disease Prediction\u0026rdquo;. See his homepage for more information.","tags":null,"title":"Venet Osmani","type":"authors"},{"authors":["wenrui-fan"],"categories":null,"content":"Wenrui joined us as an AI Research Engineer (AIRE) in September 2023 and he is also pursuing his PhD in our group. He received his Master\u0026rsquo;s degree in Robotics from the University of Sheffield in 2022. Prior to that, he received Bachelor‚Äôs degree in Flight Vehicle Design from Beijing Institute of Technology, China, in 2021. See his homepage and LinkedIn page for more information.\n","date":1727913600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1727913600,"objectID":"acadd11b9c9de74e1b9f5a52196602b6","permalink":"https://haipinglu.github.io/authors/wenrui-fan/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/wenrui-fan/","section":"authors","summary":"Wenrui joined us as an AI Research Engineer (AIRE) in September 2023 and he is also pursuing his PhD in our group. He received his Master\u0026rsquo;s degree in Robotics from the University of Sheffield in 2022.","tags":null,"title":"Wenrui Fan","type":"authors"},{"authors":["lawrence-schobs"],"categories":null,"content":"Lawrence started his PhD in September 2019 and submitted his PhD dissertation \u0026ldquo;Anatomical Landmark Localisation and Uncertainty Estimation\u0026rdquo; in August 2023. He did his BSc dissertation on deep learning for landmark localisation in cardiac MRI with Haiping. His research focuses on deep learning for landmark localisation and segmentation of cardiac/brain MRI images as well as prediction performance uncertainty estimation. See his LinkedIn page for more information.\n","date":1668556800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1668556800,"objectID":"cabed566061ed185a244659d9be32f31","permalink":"https://haipinglu.github.io/authors/lawrence-schobs/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/lawrence-schobs/","section":"authors","summary":"Lawrence started his PhD in September 2019 and submitted his PhD dissertation \u0026ldquo;Anatomical Landmark Localisation and Uncertainty Estimation\u0026rdquo; in August 2023. He did his BSc dissertation on deep learning for landmark localisation in cardiac MRI with Haiping.","tags":null,"title":"Lawrence Schobs","type":"authors"},{"authors":["hao-xu"],"categories":null,"content":"Hao was an MSc dissertation student working with us on predicting the side effects of taking multiple drugs (poly-pharmacy) using graph neural networks. She was Haiping\u0026rsquo;s second student winning the best dissertation award in the department. She then joined our collaborator\u0026rsquo;s lab in Canada as a Research Assistant until she started her PhD study at the University of California, San Diego in 2022. See her LinkedIn page for more information.\n","date":1665964800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1665964800,"objectID":"9e7a10ec58d08e397a4a4c3cce633a46","permalink":"https://haipinglu.github.io/authors/hao-xu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/hao-xu/","section":"authors","summary":"Hao was an MSc dissertation student working with us on predicting the side effects of taking multiple drugs (poly-pharmacy) using graph neural networks. She was Haiping\u0026rsquo;s second student winning the best dissertation award in the department.","tags":null,"title":"Hao Xu","type":"authors"},{"authors":["raivo-koot"],"categories":null,"content":"Raivo started doing research with us in 2020 and he is now doing his BSc dissertation with Haiping. His research focuses on action recognition with transformer (deep learning) models. See his LinkedIn page for more information.\n","date":1665964800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1665964800,"objectID":"1d3dbdbc1c0f3329b8678a8bde0b0814","permalink":"https://haipinglu.github.io/authors/raivo-koot/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/raivo-koot/","section":"authors","summary":"Raivo started doing research with us in 2020 and he is now doing his BSc dissertation with Haiping. His research focuses on action recognition with transformer (deep learning) models. See his LinkedIn page for more information.","tags":null,"title":"Raivo Koot","type":"authors"},{"authors":["li-zhang"],"categories":null,"content":"Li started her PhD in September 2017 and submitted her PhD dissertation \u0026ldquo;Exploring Local Information for Graph Representation Learning\u0026rdquo; in September 2021. In 2020/21, she spent most of time at Baidu China for an internship. See her LinkedIn page for more information.\n","date":1643673600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1640785829,"objectID":"2b6f30d8757a48a4e1a10cbc9eaf575e","permalink":"https://haipinglu.github.io/authors/li-zhang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/li-zhang/","section":"authors","summary":"Li started her PhD in September 2017 and submitted her PhD dissertation \u0026ldquo;Exploring Local Information for Graph Representation Learning\u0026rdquo; in September 2021. In 2020/21, she spent most of time at Baidu China for an internship.","tags":null,"title":"Li Zhang","type":"authors"},{"authors":["yan-ge"],"categories":null,"content":"Yan joined us in September 2017 and submitted his PhD dissertation \u0026ldquo;Representation Learning with Motif Structures\u0026rdquo; in June 2021. Since July 2021, he is a Lecturer in Financial Technology, Department of Computer Science, University of Bristol. His research focuses on graph-based clustering and representation. See his LinkedIn page for more information.\n","date":1638403200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1640785829,"objectID":"82489b2d2367aeb4a1c23ff5e4e78fb2","permalink":"https://haipinglu.github.io/authors/yan-ge/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/yan-ge/","section":"authors","summary":"Yan joined us in September 2017 and submitted his PhD dissertation \u0026ldquo;Representation Learning with Motif Structures\u0026rdquo; in June 2021. Since July 2021, he is a Lecturer in Financial Technology, Department of Computer Science, University of Bristol.","tags":null,"title":"Yan Ge","type":"authors"},{"authors":["alexandra-herghelegiu"],"categories":null,"content":"Alexandra was a BSc student working on graph neural networks for biological applications from 2020 to 2021 at the University of Sheffield. She finished her BSc dissertation \u0026ldquo;Improving negative sampling in graph neural networks for drug-drug interaction prediction\u0026rdquo; under Haiping\u0026rsquo;s supervision in 2021, after which she joined Apple. See her LinkedIn page for more information.\n","date":1638316800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1645008328,"objectID":"c4446469ff13662d1f7e2b502adaeb87","permalink":"https://haipinglu.github.io/authors/alexandra-herghelegiu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/alexandra-herghelegiu/","section":"authors","summary":"Alexandra was a BSc student working on graph neural networks for biological applications from 2020 to 2021 at the University of Sheffield. She finished her BSc dissertation \u0026ldquo;Improving negative sampling in graph neural networks for drug-drug interaction prediction\u0026rdquo; under Haiping\u0026rsquo;s supervision in 2021, after which she joined Apple.","tags":null,"title":"Alexandra Herghelegiu","type":"authors"},{"authors":["yang-zhou"],"categories":null,"content":"Yang was my second PhD student at Hong Kong and he joined in April 2015. His research focused on probabilistic models for tensor analysis and feature extraction. I left Hong Kong in 2016 and continued providing guidance remotely. He joined National University of Singapore after finishing his PhD. See his homepage for more information.\n","date":1625097600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1640785815,"objectID":"11473edf4541a26edb3aeaf6c0f27949","permalink":"https://haipinglu.github.io/authors/yang-zhou/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/yang-zhou/","section":"authors","summary":"Yang was my second PhD student at Hong Kong and he joined in April 2015. His research focused on probabilistic models for tensor analysis and feature extraction. I left Hong Kong in 2016 and continued providing guidance remotely.","tags":null,"title":"Yang Zhou","type":"authors"},{"authors":["gaolang-gong"],"categories":null,"content":"We started collaborating with Gaolang in 2019. We work on domain adaptation for brain disease diagnosis and neuroscience studies using brain imaging and other related data. See his profile page for more information.\n","date":1622592e3,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1640785820,"objectID":"82273f4dff6564e758d3bf158d51dbc6","permalink":"https://haipinglu.github.io/authors/gaolang-gong/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/gaolang-gong/","section":"authors","summary":"We started collaborating with Gaolang in 2019. We work on domain adaptation for brain disease diagnosis and neuroscience studies using brain imaging and other related data. See his profile page for more information.","tags":null,"title":"Gaolang Gong","type":"authors"},{"authors":["johanna-uthoff"],"categories":null,"content":"Jo was a Postdoctoral Research Associate with us for two years from Oct 2019 to Sep 2021. She worked on the Wellcome Trust project on machine learning for diagnosis, prognosis, and treatment assessment of cardiovascular diseases using cardiac MRI. See her LinkedIn page for more information.\n","date":1617235200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1640785828,"objectID":"c6a13d1a5248913a9d6aab23ca140057","permalink":"https://haipinglu.github.io/authors/johanna-uthoff/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/johanna-uthoff/","section":"authors","summary":"Jo was a Postdoctoral Research Associate with us for two years from Oct 2019 to Sep 2021. She worked on the Wellcome Trust project on machine learning for diagnosis, prognosis, and treatment assessment of cardiovascular diseases using cardiac MRI.","tags":null,"title":"Johanna Uthoff","type":"authors"},{"authors":["wenwen-li"],"categories":null,"content":"Wenwen was the first postdoctoral researcher in our group. She worked on an EPSRC-funded project developing tensor-based machine learning with sparsity for brain fMRI classification from June 2018 to June 2019. She joined University of Edinburgh after leaving Sheffield. See her LinkedIn page for more information.\n","date":1580515200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1640785817,"objectID":"815ccd3aa19ebd970521fea337d6b786","permalink":"https://haipinglu.github.io/authors/wenwen-li/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/wenwen-li/","section":"authors","summary":"Wenwen was the first postdoctoral researcher in our group. She worked on an EPSRC-funded project developing tensor-based machine learning with sparsity for brain fMRI classification from June 2018 to June 2019.","tags":null,"title":"Wenwen Li","type":"authors"},{"authors":["qiquan-shi"],"categories":null,"content":"Qiquan was my first ever PhD student, when I started my faculty career at Hong Kong Baptist University. He started in September 2014 and focused on tensor completion for his PhD dissertation. I left Hong Kong in 2016 and continued providing guidance remotely. He joined Huawei after finishing his PhD. See his LinkedIn page for more information.\n","date":1559347200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1640785811,"objectID":"900f288818266dc54befaaffac90f95c","permalink":"https://haipinglu.github.io/authors/qiquan-shi/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/qiquan-shi/","section":"authors","summary":"Qiquan was my first ever PhD student, when I started my faculty career at Hong Kong Baptist University. He started in September 2014 and focused on tensor completion for his PhD dissertation.","tags":null,"title":"Qiquan Shi","type":"authors"},{"authors":["alan-thomas"],"categories":null,"content":"Alan joined us as an AI Research Engineer (AIRE) in July 2023 and he is also pursuing his PhD in our group. He received his Master\u0026rsquo;s degree in Computer Science from the University of Manchester. His research focuses on the application of generative AI and foundation models across textual, visual, audio and spatial data types.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2f28232c27c20f945fbbb7076cd54988","permalink":"https://haipinglu.github.io/authors/alan-thomas/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/alan-thomas/","section":"authors","summary":"Alan joined us as an AI Research Engineer (AIRE) in July 2023 and he is also pursuing his PhD in our group. He received his Master\u0026rsquo;s degree in Computer Science from the University of Manchester.","tags":null,"title":"Alan Thomas","type":"authors"},{"authors":["dinesh-selvarajah"],"categories":null,"content":"The collaboration with Dinesh started in October 2023 on an EPSRC-funded project \u0026ldquo;A Novel Artificial Intelligence Powered Neuroimaging Biomarker for Chronic Pain\u0026rdquo;. See his profile page for more information.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"618082d09e92a61173bdfc76db3fb6a3","permalink":"https://haipinglu.github.io/authors/dinesh-selvarajah/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/dinesh-selvarajah/","section":"authors","summary":"The collaboration with Dinesh started in October 2023 on an EPSRC-funded project \u0026ldquo;A Novel Artificial Intelligence Powered Neuroimaging Biomarker for Chronic Pain\u0026rdquo;. See his profile page for more information.","tags":null,"title":"Dinesh Selvarajah","type":"authors"},{"authors":["haolin-wang"],"categories":null,"content":"Haolin joined us as an AI Research Engineer (AIRE) in August 2023 and she is also pursuing her PhD in our group. She received her Master\u0026rsquo;s degree in Data Analytics from the University of Sheffield in 2022. Prior to that, she received her Bachelor\u0026rsquo;s degree in Mathematics from the University of Oxford in 2021. See her LinkedIn page for more information.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"62e7858b08d7c933a0688fdcad1555a5","permalink":"https://haipinglu.github.io/authors/haolin-wang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/haolin-wang/","section":"authors","summary":"Haolin joined us as an AI Research Engineer (AIRE) in August 2023 and she is also pursuing her PhD in our group. She received her Master\u0026rsquo;s degree in Data Analytics from the University of Sheffield in 2022.","tags":null,"title":"Haolin Wang","type":"authors"},{"authors":["jiayang-zhang"],"categories":null,"content":"Jiayang joined us as an AI Research Engineer (AIRE) in March 2024. She recieved her Bachelor\u0026rsquo;s and Master\u0026rsquo;s degree in Physics from Imperial College London. See her LinkedIn page for more information.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"fedb47a3f0c7ffe843a54ae9730ecbb1","permalink":"https://haipinglu.github.io/authors/jiayang-zhang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/jiayang-zhang/","section":"authors","summary":"Jiayang joined us as an AI Research Engineer (AIRE) in March 2024. She recieved her Bachelor\u0026rsquo;s and Master\u0026rsquo;s degree in Physics from Imperial College London. See her LinkedIn page for more information.","tags":null,"title":"Jiayang Zhang","type":"authors"},{"authors":["katerina-christofidou"],"categories":null,"content":"The collaboration with Kathy started in December 2023 on an AI Research Engineering project \u0026ldquo;Digital Materials Discovery\u0026rdquo;. See her profile page for more information.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"cdb62e2d06137ea4eb476374e9d66804","permalink":"https://haipinglu.github.io/authors/katerina-christofidou/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/katerina-christofidou/","section":"authors","summary":"The collaboration with Kathy started in December 2023 on an AI Research Engineering project \u0026ldquo;Digital Materials Discovery\u0026rdquo;. See her profile page for more information.","tags":null,"title":"Kathy Christofidou","type":"authors"},{"authors":["riza-rizky"],"categories":null,"content":"Riza joined us as an AI Research Engineer (AIRE) in April 2024. He recieved his Master\u0026rsquo;s degree in Artificial Intelligence from The University of Edinburgh. See his LinkedIn page for more information.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"8e5a8210fa3b9e79edd016e11e8bd781","permalink":"https://haipinglu.github.io/authors/riza-rizky/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/riza-rizky/","section":"authors","summary":"Riza joined us as an AI Research Engineer (AIRE) in April 2024. He recieved his Master\u0026rsquo;s degree in Artificial Intelligence from The University of Edinburgh. See his LinkedIn page for more information.","tags":null,"title":"Lalu Muhammad Riza Rizky","type":"authors"},{"authors":["nicola-morley"],"categories":null,"content":"The collaboration with Nicola started in December 2023 on an AI Research Engineering project \u0026ldquo;Digital Materials Discovery\u0026rdquo;. See her profile page for more information.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"e79a94e86f1ff7890bf769b2f8a797a8","permalink":"https://haipinglu.github.io/authors/nicola-morley/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/nicola-morley/","section":"authors","summary":"The collaboration with Nicola started in December 2023 on an AI Research Engineering project \u0026ldquo;Digital Materials Discovery\u0026rdquo;. See her profile page for more information.","tags":null,"title":"Nicola Morley","type":"authors"},{"authors":["pawel-pukowski"],"categories":null,"content":"Pawel joined us in November 2021. He did his BSc dissertation on hand segmentation for action recognition with Haiping. His research focuses on developing theoretical models for deep learning algorithms. See his LinkedIn page for more information.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"49cbfb7ad5dfbfe9c51b3c5ffe7f981d","permalink":"https://haipinglu.github.io/authors/pawel-pukowski/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/pawel-pukowski/","section":"authors","summary":"Pawel joined us in November 2021. He did his BSc dissertation on hand segmentation for action recognition with Haiping. His research focuses on developing theoretical models for deep learning algorithms. See his LinkedIn page for more information.","tags":null,"title":"Pawel Pukowski","type":"authors"},{"authors":["reza-rastegari"],"categories":null,"content":"Reza is a remote intern at the University of Sheffield starting Sep 2024. He is currently working on graph neural networks for protein-metal binding prediction. See his LinkedIn page for more information.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"8027e53d7deb6ba5fbf93906c75dc8ea","permalink":"https://haipinglu.github.io/authors/reza-rastegari/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/reza-rastegari/","section":"authors","summary":"Reza is a remote intern at the University of Sheffield starting Sep 2024. He is currently working on graph neural networks for protein-metal binding prediction. See his LinkedIn page for more information.","tags":null,"title":"Reza Rastegari","type":"authors"},{"authors":["sina-tabakhi"],"categories":null,"content":"Sina joined us in November 2021. Before joining our team, he had worked in the industry as a software engineer for five years. Sina has also developed a feature selection tool, Universal Feature Selection Tool (UniFeat), from his Master\u0026rsquo;s work. He has started conducting research on multi-omics data integration by feature selection to obtain a deep understanding of molecular mechanisms. See his homepage for more information.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"f56d4f47960bffcb3ebc00c2a0da20c8","permalink":"https://haipinglu.github.io/authors/sina-tabakhi/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/sina-tabakhi/","section":"authors","summary":"Sina joined us in November 2021. Before joining our team, he had worked in the industry as a software engineer for five years. Sina has also developed a feature selection tool, Universal Feature Selection Tool (UniFeat), from his Master\u0026rsquo;s work.","tags":null,"title":"Sina Tabakhi","type":"authors"},{"authors":["sokratis-kariotis"],"categories":null,"content":"Sokratis joined us in September 2018, working under the joint supervision of Dennis Wang and Haiping on unsupervised machine learning of high dimensional data for patient stratification. See his LinkedIn page for more information.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"29e15f23cc46f2ac80bb0e480061fb77","permalink":"https://haipinglu.github.io/authors/sokratis-kariotis/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/sokratis-kariotis/","section":"authors","summary":"Sokratis joined us in September 2018, working under the joint supervision of Dennis Wang and Haiping on unsupervised machine learning of high dimensional data for patient stratification. See his LinkedIn page for more information.","tags":null,"title":"Sokratis Kariotis","type":"authors"},{"authors":["wei-sang"],"categories":null,"content":"We started collaborating with Wei in August 2024. We work on interpretable multimodal learning for prediction and regulation of tumor protein-metal binding.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"73bccc21d2b843ef3fb8f5092951580e","permalink":"https://haipinglu.github.io/authors/wei-sang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/wei-sang/","section":"authors","summary":"We started collaborating with Wei in August 2024. We work on interpretable multimodal learning for prediction and regulation of tumor protein-metal binding.","tags":null,"title":"Wei Sang","type":"authors"},{"authors":["yingjie-guo"],"categories":null,"content":"We started collaborating with Yingjie in July 2024. We work on single-cell multi-omics data integration.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"6c09823b0ab468d31ee5e4407bc0b57e","permalink":"https://haipinglu.github.io/authors/yingjie-guo/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/yingjie-guo/","section":"authors","summary":"We started collaborating with Yingjie in July 2024. We work on single-cell multi-omics data integration.","tags":null,"title":"Yingjie Guo","type":"authors"},{"authors":null,"categories":null,"content":"üëã Welcome to the Academic Template The Wowchemy Academic Resum√© Template for Hugo empowers you to create your job-winning online resum√© and showcase your academic publications.\nCheck out the latest demo of what you\u0026rsquo;ll get in less than 10 minutes, or view the showcase.\nWowchemy makes it easy to create a beautiful website for free. Edit your site in Markdown, Jupyter, or RStudio (via Blogdown), generate it with Hugo, and deploy with GitHub or Netlify. Customize anything on your site with widgets, themes, and language packs.\n üëâ Get Started üìö View the documentation üí¨ Chat with the Wowchemy community or Hugo community üê¶ Twitter: @wowchemy @GeorgeCushen #MadeWithWowchemy üí° Request a feature or report a bug for Wowchemy ‚¨ÜÔ∏è Updating Wowchemy? View the Update Guide and Release Notes  Crowd-funded open-source software To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.\n‚ù§Ô∏è Click here to unlock rewards with sponsorship You\u0026rsquo;re looking at a Wowchemy widget  This homepage section is an example of adding elements to the Blank widget.\nBackgrounds can be applied to any section. Here, the background option is set give a color gradient.\nTo remove this section, delete content/home/demo.md.\n  Get inspired Check out the Markdown files which power the Academic Demo, or view the showcase.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"1d1825344e8f4b25c2137e0a9c8b655f","permalink":"https://haipinglu.github.io/home-unused/demo/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/demo/","section":"home-unused","summary":"üëã Welcome to the Academic Template The Wowchemy Academic Resum√© Template for Hugo empowers you to create your job-winning online resum√© and showcase your academic publications.\nCheck out the latest demo of what you\u0026rsquo;ll get in less than 10 minutes, or view the showcase.","tags":null,"title":"Academic Template","type":"home-unused"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"4a7e3501655fed0a4b0ce814e15ff2c9","permalink":"https://haipinglu.github.io/home-unused/skills/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/skills/","section":"home-unused","summary":"","tags":null,"title":"Skills","type":"home-unused"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"d6682c06ff2f3dd0fc28f7e2c0702d07","permalink":"https://haipinglu.github.io/home-unused/experience/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/experience/","section":"home-unused","summary":"","tags":null,"title":"Experience","type":"home-unused"},{"authors":null,"categories":null,"content":"Profiles: Google Scholar, ResearcherID, ScopusAuthorID, Semantic Scholar.\nSee an up-to-date full list of publications in my CV (from page 2). Publications after Feb 2022 are not updated on this website due to lack of time.\nSee papers selected in 2021 below. Explore publications up to Feb 2022 \u0026gt;  to filter/search.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"28f54f6e819207239a6024bbaa9d78de","permalink":"https://haipinglu.github.io/home-unused/featured/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/featured/","section":"home-unused","summary":"Profiles: Google Scholar, ResearcherID, ScopusAuthorID, Semantic Scholar.\nSee an up-to-date full list of publications in my CV (from page 2). Publications after Feb 2022 are not updated on this website due to lack of time.","tags":null,"title":"Selected Papers","type":"home-unused"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"9e909a8894fd21a2eff4b3e43238d81e","permalink":"https://haipinglu.github.io/home-unused/accomplishments/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/accomplishments/","section":"home-unused","summary":"","tags":null,"title":"Accomplish\u0026shy;ments","type":"home-unused"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"0e643989bdefe366f2b5fddf949a36b6","permalink":"https://haipinglu.github.io/home-unused/posts/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/posts/","section":"home-unused","summary":"","tags":null,"title":"Recent Posts","type":"home-unused"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"d927b251d3da15a737d1f66fb88d4504","permalink":"https://haipinglu.github.io/home-unused/talks/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/talks/","section":"home-unused","summary":"","tags":null,"title":"Recent \u0026 Upcoming Talks","type":"home-unused"},{"authors":null,"categories":null,"content":"We develop the PyKale library in the PyTorch ecosystem to make machine learning more accessible to interdisciplinary research by bridging gaps between data, software, and end users.\n The Matlab code of algorithms and related data from my earlier works.\n Remurs (Regularized Multilinear Regression and Selection): Remurs Version 1.0: code, data, and paper (2.85MB) UMLDA¬†(Uncorrelated Multilinear Discriminant Analysis): UMLDA Version 1.1: code, data, and paper (19.73MB) RCSP¬†(Regularized Common Spatial Pattern): RCSP Version 1.0: code and paper (2.19MB) UMPCA (Uncorrelated Multilinear Principal Component Analysis): UMPCA Version 1.0: code, data, and paper (7.87MB) MPCA¬†(Multilinear Principal Component Analysis): MPCA Version 1.3 package: code, data, samples, and paper (5.18MB) Gait data: 128x88x20(21.2M); 64x44x20(9.9M); 32x22x10(3.2M) Binary Image Watermarking/Data Hiding: Binary Image Watermarking/Data Hiding: Data, Algorithms, and Distortion Measure (3.7MB)  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"5585f85d54f718a56b8cba364bf6120f","permalink":"https://haipinglu.github.io/home-unused/codedata/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/codedata/","section":"home-unused","summary":"We develop the PyKale library in the PyTorch ecosystem to make machine learning more accessible to interdisciplinary research by bridging gaps between data, software, and end users.\n The Matlab code of algorithms and related data from my earlier works.","tags":null,"title":"Code \u0026 Data","type":"home-unused"},{"authors":null,"categories":null,"content":" Quickly discover relevant content by filtering publications.   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"19cfbeefa99b41865496b68f2fb35bad","permalink":"https://haipinglu.github.io/home-unused/publications/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/publications/","section":"home-unused","summary":" Quickly discover relevant content by filtering publications.   ","tags":null,"title":"Recent Publications","type":"home-unused"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"657179738bed56748434d6ae76e8a647","permalink":"https://haipinglu.github.io/home-unused/tags/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/tags/","section":"home-unused","summary":"","tags":null,"title":"Popular Topics","type":"home-unused"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"6011477b6d615d7a4005aee5356c1e97","permalink":"https://haipinglu.github.io/home-unused/contact/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/contact/","section":"home-unused","summary":"","tags":null,"title":"Contact","type":"home-unused"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Wowchemy\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://haipinglu.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Peizhen Bai","Filip Miljkoviƒá","Xianyuan Liu","Leonardo De Maria","Rebecca Croasdale-Wood","Owen Rackham","Haiping Lu"],"categories":null,"content":"Inverse protein folding generates valid amino acid sequences that can fold into a desired protein structure, with recent deep-learning advances showing significant potential and competitive performance. However, challenges remain in predicting highly uncertain regions, such as those with loops and disorders. To tackle such low-confidence residue prediction, we propose a Mask prior-guided denoising Diffusion (MapDiff) framework that accurately captures both structural and residue interactions for inverse protein folding. MapDiff is a discrete diffusion probabilistic model that iteratively generates amino acid sequences with reduced noise, conditioned on a given protein backbone. To incorporate structural and residue interactions, we develop a graph-based denoising network with a mask prior pre-training strategy. Moreover, in the generative process, we combine the denoising diffusion implicit model with Monte-Carlo dropout to improve uncertainty estimation. Evaluation on four challenging sequence design benchmarks shows that MapDiff significantly outperforms state-of-the-art methods. Furthermore, the in-silico sequences generated by MapDiff closely resemble the physico-chemical and structural characteristics of native proteins across different protein families and architectures.\n","date":1733788800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1733788800,"objectID":"a485e5fabe6f0ba54f10344515ac46df","permalink":"https://haipinglu.github.io/project/inverse-protein-folding/","publishdate":"2024-12-10T00:00:00Z","relpermalink":"/project/inverse-protein-folding/","section":"project","summary":"Design proteins using mask prior-guided denoising diffusion for inverse protein folding","tags":["AI4Science","Protein Engineering","Generative AI","Selected"],"title":"Inverse protein folding via denoising diffusion","type":"project"},{"authors":["Mohammod Suvon","Prasun Tripathi","Wenrui Fan","Shuo Zhou","Xianyuan Liu","Samer Alabed","Venet Osmani","Andrew Swift","Chen Chen","Haiping Lu"],"categories":null,"content":"This project is a Wellcome Trust Innovator Awards: Digital Technologies.\nCardiovascular diseases account for 26% of deaths in the UK. Current clinical imaging assessments rely on manual or semi-automated measurements. Emerging approaches focus on individual parts of the heart. We have developed the first tensor-based machine learning approach that holistically assesses the heart and surrounding structures on cardiovascular magnetic resonance imaging (CMRI) scans. We will develop this approach into a tool that can identify patients who respond to treatment or who will die early. Key advantages are rapid holistic assessment, minimal human error and full transparency with direct visualisation of features for the disease. We will assemble a large cohort of CMRI scans from 5, 000 patients with pulmonary hypertension, a severe condition affecting the heart, and assess the ability to predict treatment response and likelihood of early death. This tool will revolutionise disease assessment, and improve treatment delivery and patient care.\n","date":1727913600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1727913600,"objectID":"e635c5256c8210c6b883c7894cbf071d","permalink":"https://haipinglu.github.io/project/multimodal-vae-low-cost-cardiac/","publishdate":"2024-10-03T00:00:00Z","relpermalink":"/project/multimodal-vae-low-cost-cardiac/","section":"project","summary":"Develop a cost-effective cardiac instability detection tool using multimodal variational autoencoder","tags":["Multimodal AI","AI4Health","Selected"],"title":"Multimodal VAE for low-cost cardiac assessment","type":"project"},{"authors":["Peizhen Bai","Xianyuan Liu","Haiping Lu"],"categories":null,"content":"Molecular property prediction with deep learning has gained much attention over the past years. Owing to the scarcity of labeled molecules, there has been growing interest in self-supervised learning methods that learn generalizable molecular representations from unlabeled data. Molecules are typically treated as 2D topological graphs in modeling, but it has been discovered that their 3D geometry is of great importance in determining molecular functionalities. In this paper, we propose the Geometry-aware line graph transformer (Galformer) pre-training, a novel self-supervised learning framework that aims to enhance molecular representation learning with 2D and 3D modalities. Specifically, we first design a dual-modality line graph transformer backbone to encode the topological and geometric information of a molecule. The designed backbone incorporates effective structural encodings to capture graph structures from both modalities. Then we devise two complementary pre-training tasks at the inter and intra-modality levels. These tasks provide properly supervised information and extract discriminative 2D and 3D knowledge from unlabeled molecules. Finally, we evaluate Galformer against six state-of-the-art baselines on twelve property prediction benchmarks via downstream fine-tuning. Experimental results show that Galformer consistently outperforms all baselines on both classification and regression tasks, demonstrating its effectiveness.\n","date":1693526400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1693526400,"objectID":"89e7846e9e4a3c320bbf6fb4aa92ceaf","permalink":"https://haipinglu.github.io/project/molecular-property-prediction/","publishdate":"2023-09-01T00:00:00Z","relpermalink":"/project/molecular-property-prediction/","section":"project","summary":"Predict molecular properties with geometry-aware line graph transformer pre-training","tags":["Multimodal AI","AI4Science","Selected"],"title":"Molecular property prediction via line graph transformer","type":"project"},{"authors":["Peizhen Bai","Filip Miljkoviƒá","Bino John","Haiping Lu"],"categories":null,"content":"Predicting drug‚Äìtarget interaction is key for drug discovery. Recent deep learning-based methods show promising performance, but two challenges remain: how to explicitly model and learn local interactions between drugs and targets for better prediction and interpretation and how to optimize generalization performance of predictions on novel drug‚Äìtarget pairs. Here, we present DrugBAN, a deep Bilinear Attention Network (BAN) framework with domain adaptation to explicitly learn pairwise local interactions between drugs and targets, and adapt in response to out-of-distribution data. DrugBAN works on drug molecular graphs and target protein sequences to perform prediction, with conditional domain adversarial learning to align learned interaction representations across different distributions for better generalization on novel drug‚Äìtarget pairs. Experiments on three benchmark datasets under both in-domain and cross-domain settings show that DrugBAN achieves the best overall performance against five state-of-the-art baseline models. Moreover, visualizing the learned bilinear attention map provides interpretable insights from prediction results.\n","date":1675209600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1675209600,"objectID":"a789709d601923448defc5474f992a5f","permalink":"https://haipinglu.github.io/project/drug-target-interaction-prediction/","publishdate":"2023-02-01T00:00:00Z","relpermalink":"/project/drug-target-interaction-prediction/","section":"project","summary":"Advance drug discovery with interpretable bilinear attention network and domain adaptation","tags":["Multimodal AI","AI4Health","AI4Science","Selected"],"title":"Drug‚Äìtarget interaction prediction via bilinear attention network","type":"project"},{"authors":["Lawrence Schobs","Andrew Swift","Haiping Lu"],"categories":null,"content":"Automatic anatomical landmark localisation has made great strides by leveraging deep learning methods in recent years. The ability to quantify the uncertainty of these predictions is a vital ingredient needed to see these methods adopted in clinical use, where it is imperative that erroneous predictions are caught and corrected.\nWe propose Quantile Binning, a data-driven method to categorise predictions by uncertainty with estimated error bounds. This framework can be applied to any continuous uncertainty measure, allowing straightforward identification of the best subset of predictions with accompanying estimated error bounds. We facilitate easy comparison between uncertainty measures by constructing two evaluation metrics derived from Quantile Binning. We demonstrate this framework by comparing and contrasting three uncertainty measures (a baseline, the current gold standard, and a proposed method combining aspects of the two), across two datasets (one easy, one hard) and two heatmap-based landmark localisation model paradigms (U-Net based and patch-based). We conclude by illustrating how filtering out gross mispredictions caught in our Quantile Bins significantly improves the proportion of predictions under an acceptable error threshold, and offer recommendations on which uncertainty measure to use and how to use it.\n","date":1668556800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668556800,"objectID":"974f2385ec78669aa7be7aedb27df386","permalink":"https://haipinglu.github.io/project/landmark-uncertainty/","publishdate":"2022-11-16T00:00:00Z","relpermalink":"/project/landmark-uncertainty/","section":"project","summary":"Quantify the uncertainty in automatic anatomical landmark localisation","tags":["AI4Health","Medical Imaging","Interpretable Machine Learning"],"title":"Uncertainty estimation for landmark localisation","type":"project"},{"authors":["Haiping Lu","Xianyuan Liu","Shuo Zhou","Robert Turner","Peizhen Bai","Raivo Koot","Mustafa Chasmai","Lawrence Schobs","Hao Xu"],"categories":null,"content":"PyKale is a library in the PyTorch ecosystem aiming to make machine learning more accessible to interdisciplinary research by bridging gaps between data, software, and end users. Both machine learning experts and end users can do better research with our accessible, scalable, and sustainable design, guided by green machine learning principles. PyKale has a unified pipeline-based API and focuses on multimodal learning and transfer learning for graphs, images, texts, and videos at the moment, with supporting models on deep learning and dimensionality reduction.\nPyKale enforces standardization and minimalism, via green machine learning concepts of reducing repetitions and redundancy, reusing existing resources, and recycling learning models across areas. PyKale will enable and accelerate interdisciplinary, knowledge-aware machine learning research for graphs, images, texts, and videos in applications including bioinformatics, graph analysis, image/video recognition, and medical imaging, with an overarching theme of leveraging knowledge from multiple sources for accurate and interpretable prediction.\n","date":1665964800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1665964800,"objectID":"010f4f82cabbfca138d8fb57359f21be","permalink":"https://haipinglu.github.io/project/pykale/","publishdate":"2022-10-17T00:00:00Z","relpermalink":"/project/pykale/","section":"project","summary":"Enable accessible machine learning from multiple data sources for interdisciplinary research","tags":["Multimodal AI","AI4Health","AI4Science","Selected"],"title":"PyKale: open-source multimodal learning software library","type":"project"},{"authors":["Li Zhang","Lei Shi","Jiashu Zhao","Juan Yang","Tianshu Lyu","Dawei Yin","Haiping Lu"],"categories":[],"content":"","date":1643673600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785759,"objectID":"c62c790d6a75c0d891ebe51d1d0aaacc","permalink":"https://haipinglu.github.io/publication/zhang-2021-gnn/","publishdate":"2021-12-29T13:49:17.680056Z","relpermalink":"/publication/zhang-2021-gnn/","section":"publication","summary":"Watching online videos has become more and more popular and users tend to watch videos based on their personal tastes and preferences. Providing a customized ranking list to maximize the user‚Äôs satisfaction has become increasingly important for online video platforms. Existing personalized search methods (PSMs) train their models with user feedback information (e.g. clicks). However, we identified that such feedback signals may indicate attractiveness but not necessarily indicate relevance in video search. Besides, the click data and user historical information are usually too sparse to train a good PSM, which is different from the conventional Web search containing users‚Äô rich historical information. To address these concerns, in this paper we propose a multi-task graph neural network architecture for personalized video search (MGNN-PVS) that can jointly model user‚Äôs click behaviour and the relevance between queries and videos. To relieve the sparsity problem and learn better representation for users, queries and videos, we develop an efficient and novel GNN architecture based on neighborhood sampling and hierarchical aggregation strategy by leveraging their different hops of neighbors in the user-query and query-document click graph. Extensive experiments on a major commercial video search engine show that our model significantly outperforms stateof-the-art PSMs, which illustrates the effectiveness of our proposed framework.","tags":[],"title":"A GNN-based multi-task learning framework for personalized video search","type":"publication"},{"authors":["Krit Dwivedi","Robin Condliffe","Michael Sharkey","Robert Lewis","Samer Alabed","Smitha Rajaram","Catherine Hill","Laura Saunders","Peter Metherall","Faisal Alandejani","Dheyaa Alkhanfar","Jim M. Wild","Haiping Lu","David Kiely","Andrew Swift"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645008329,"objectID":"550efe502e0bfe3e98488fdee6bcd77d","permalink":"https://haipinglu.github.io/publication/dwivedi-2022-computed/","publishdate":"2022-02-16T10:45:28.554084Z","relpermalink":"/publication/dwivedi-2022-computed/","section":"publication","summary":"Background: Patients with pulmonary hypertension (PH) and lung disease may pose a diagnostic dilemma between idiopathic pulmonary arterial hypertension (IPAH) and PH associated with lung disease (PH-CLD). The prognostic impact of common computed tomography (CT) parenchymal features is unknown. Methods: 660 IPAH and PH-CLD patients assessed between 2001 and 2019 were included. Reports for all CT scans 1‚ÄÖyear prior to diagnosis were analysed for common lung parenchymal patterns. Cox regression and Kaplan‚ÄìMeier analysis were performed. Results: At univariate analysis of the whole cohort, centrilobular ground-glass (CGG) changes (hazard ratio, HR 0.29) and ground-glass opacification (HR 0.53) predicted improved survival, while honeycombing (HR 2.79), emphysema (HR 2.09) and fibrosis (HR 2.38) predicted worse survival (all p","tags":[],"title":"Computed tomography lung parenchymal descriptions in routine radiological reporting have diagnostic and prognostic utility in patients with idiopathic pulmonary arterial hypertension and pulmonary hypertension associated with lung disease","type":"publication"},{"authors":["Peizhen Bai","Filip Miljkoviƒá","Bino John","Haiping Lu"],"categories":null,"content":"This project is in collaboration with AstraZeneca.\nDrug-target interaction (DTI) prediction is important in drug discovery and chemogenomics studies. Machine learning, particularly deep learning, has advanced this area significantly over the past few years. However, a significant gap between the performance reported in academic papers and that in practical drug discovery settings, e.g. the random-split-based evaluation strategy tends to be too optimistic in estimating the prediction performance in real-world settings. Such performance gap is largely due to hidden data bias in experimental datasets and inappropriate data split.\nIn this project, we construct a low-bias DTI dataset and study more challenging data split strategies to improve performance evaluation for real-world settings. Specifically, we study the data bias in a popular DTI dataset, BindingDB, and re-evaluate the prediction performance of three state-of-the-art deep learning models using five different data split strategies: random split, cold drug split, scaffold split, and two hierarchical-clustering-based splits. In addition, we comprehensively examine six performance metrics. Our experimental results confirm the overoptimism of the popular random split and show that hierarchical-clustering-based splits are far more challenging and can provide potentially more useful assessment of model generalizability in real-world DTI prediction settings.\n","date":1639180800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1639180800,"objectID":"9632445c7e92e8448fe40a0411cbb8fd","permalink":"https://haipinglu.github.io/project-removed/dti-graph-eval/","publishdate":"2021-12-11T00:00:00Z","relpermalink":"/project-removed/dti-graph-eval/","section":"project-removed","summary":"Hierarchical clustering split for low-bias evaluation of drug-target interaction prediction","tags":["Graph Machine Learning","Deep Learning","Bioinformatics"],"title":"Low-Bias Evaluation of Drug-Target Interaction","type":"project-removed"},{"authors":["Peizhen Bai","Filip Miljkoviƒá","Yan Ge","Nigel Greene","Bino John","Haiping Lu"],"categories":[],"content":"","date":1638403200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785760,"objectID":"18e7374d1847c9dfdd5983c6af3b2650","permalink":"https://haipinglu.github.io/publication/bai-2021-hierarchical/","publishdate":"2021-12-29T13:49:20.010812Z","relpermalink":"/publication/bai-2021-hierarchical/","section":"publication","summary":"Drug-target interaction (DTI) prediction is important in drug discovery and chemogenomics studies. Machine learning, particularly deep learning, has advanced this area significantly over the past few years. However, a significant gap between the performance reported in academic papers and that in practical drug discovery settings, e.g. the random-split-based evaluation strategy tends to be too optimistic in estimating the prediction performance in real-world settings. Such performance gap is largely due to hidden data bias in experimental datasets and inappropriate data split. In this paper, we construct a low-bias DTI dataset and study more challenging data split strategies to improve performance evaluation for real-world settings. Specifically, we study the data bias in a popular DTI dataset, BindingDB, and re-evaluate the prediction performance of three state-of-the-art deep learning models using five different data split strategies: random split, cold drug split, scaffold split, and two hierarchical-clustering-based splits. In addition, we comprehensively examine six performance metrics. Our experimental results confirm the overoptimism of the popular random split and show that hierarchical-clustering-based splits are far more challenging and can provide potentially more useful assessment of model generalizability in real-world DTI prediction settings.","tags":[],"title":"Hierarchical clustering split for low-bias evaluation of drug-target interaction prediction","type":"publication"},{"authors":["Alexandra Herghelegiu","Haiping Lu"],"categories":[],"content":"","date":1638316800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645008328,"objectID":"ff099478bb8d34f3b607b97925898e06","permalink":"https://haipinglu.github.io/publication/herghelegiu-2021-improving/","publishdate":"2022-02-16T10:45:21.341899Z","relpermalink":"/publication/herghelegiu-2021-improving/","section":"publication","summary":"Predicting drug-drug interactions (DDIs) becomes an increasingly important problem in the computational domain, due to the acceleration of drug discovery and the high costs of solving this task through in vitro experiments. It can be modelled as a link prediction task on a DDIs network, where each node represents a drug and each link represents a meaningful interaction between a pair of drugs. Graph Neural Networks (GNNs) have achieved state-of-the-art results in node classification and graph classification and consequently there is an increasing interest into their application on link prediction. The well-established GNN-based encoder-decoder framework requires negative links (i.e. non-interactions) for training, as it is performed in a supervised fashion. Most of the current DDI datasets do not provide laboratory-confirmed negative interactions (i.e. non-interacting pairs of drugs) and so negative sampling from the unobserved links becomes an exclusively computational task.There is a lack of research investigating the quality and importance of negative sampling techniques when predicting on homogeneous graphs. This paper focuses on improving negative sampling in GNNs on a homogeneous drug-drug interaction graph. An analysis into the effect of negative sampling on predicting DDIs in such a network is carried out and current approaches are formalised and tested. Following this, LANS, a novel Loss-based Adaptive Negative Sampling technique, is introduced. The lightweight LANS method achieves an increase in performance of 16.49% in the Hits@20 metric without adding any trainable parameters to the architecture. Finally, some of its limitations are identified and potential improvements are proposed.","tags":[],"title":"Improving Negative Sampling in Graph Neural Networks for Predicting Drug-Drug Interactions","type":"publication"},{"authors":["Raivo Koot","Markus Hennerbichler","Haiping Lu"],"categories":[],"content":"","date":1635724800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785834,"objectID":"85605d1cc2b7d172d6d75ad8f6af67b3","permalink":"https://haipinglu.github.io/publication/koot-2021-evaluating/","publishdate":"2021-12-29T13:50:34.190688Z","relpermalink":"/publication/koot-2021-evaluating/","section":"publication","summary":"In video action recognition, transformers consistently reach state-of-the-art accuracy. However, many models are too heavyweight for the average researcher with limited hardware resources. In this work, we explore the limitations of video transformers for lightweight action recognition. We benchmark 13 video transformers and baselines across 3 large-scale datasets and 10 hardware devices. Our study is the first to evaluate the efficiency of action recognition models in depth across multiple devices and train a wide range of video transformers under the same conditions. We categorize current methods into three classes and show that composite transformers that augment convolutional backbones are best at lightweight action recognition, despite lacking accuracy. Meanwhile, attention-only models need more motion modeling capabilities and stand-alone attention block models currently incur too much latency overhead. Our experiments conclude that current video transformers are not yet capable of lightweight action recognition on par with traditional convolutional baselines, and that the previously mentioned shortcomings need to be addressed to bridge this gap. Code to reproduce our experiments will be made publicly available.","tags":[],"title":"Evaluating transformers for lightweight action recognition","type":"publication"},{"authors":["Andrew Swift","Haiping Lu"],"categories":null,"content":"This project is an NIHR AI in Health and Care Award.\nCardiovascular and pulmonary diseases account for close to half of all deaths in the UK. Diagnosing individuals with such conditions correctly and predicting whether they will respond to treatment is important to guide therapeutic intervention and achieve optimal outcomes. Cardiac magnetic resonance imaging (CMRI) and computed tomography (CT) scans are key to cardiac and pulmonary diagnosis. Current assessments are made by manual measurements (contours or landmarks) to derive meaningful information of heart function, or physiological parameters that are time-consuming and suffer from variability between individuals due to human error. Artificial intelligence using deep learning is pushing the limit of image analysis to an unprecedented level. Recently, a deep learning-based method trained on scans with high variability has been shown to achieve fully automated assessment of the left ventricle (LV) on CMRI. However, this level of automation has not been achieved for the right ventricle (RV) or the atrial chambers. RV failure is the key determinant of death in many cardiac conditions, but accurate RV assessment by human observers is challenging due to the more subtle anatomy and the thinner structures. There is a real clinical need to develop a fully automated assessment of the RV and all four cardiac chambers to derive meaningful physiological parameters.\nThe aim of this project is to develop an interactive human-in-the-loop multi-stage deep learning method to measure the health of the heart in large cohorts of patients with different cardiac and pulmonary conditions, scanned on different MRI/CT machines. This method will automatically generate physiological parameters and assess their ability to automatically predict treatment response and early death. In addition, we will assess the ability of machine learning to directly assess complex shape or/and motion of the heart to make a prognostic assessment from the automatic drawings on the heart.\nExisting contour and landmark detection algorithms (known from our pilot assessments to be suboptimal) will be applied to scans of a large cohort of patients from different hospitals with diverse cardiac and pulmonary conditions. The measurements will be edited by a team of experienced consultants, these revised contours and landmarks will be fed back into the training to achieve an improved segmentation, and the process will repeat three times to achieve ideal accuracy. Feedback will be sought from doctors, imaging experts and patients.The deep learnt assessment of the heart will provide important measurements for predicting therapy response and survival in individuals with cardiac disease. The automatic physiological parameters and assessment of complex shape or/and motion produced by the deep learning approach could revolutionise disease assessment, and improve treatment delivery and patient care. Key advantages are rapid assessment, minimised human error and more consistent reporting of cardiac physiology and function.\n","date":1633046400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633046400,"objectID":"e5f86fbbe0bc646c1281142f6c9be447","permalink":"https://haipinglu.github.io/project-removed/cardiac-hitl-dl/","publishdate":"2021-10-01T00:00:00Z","relpermalink":"/project-removed/cardiac-hitl-dl/","section":"project-removed","summary":"Interactively trained 'human-in-the-loop' deep learning to improve cardiac CT/MRI assessment for accurate therapy response and mortality prediction","tags":["Deep Learning","Medical Imaging"],"title":"Human-in-the-loop DL for cardiac CT/MRI","type":"project-removed"},{"authors":["Yan Ge","Pan Peng","Haiping Lu"],"categories":[],"content":"","date":1630454400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785827,"objectID":"87b46c7ecbf5b1d4556f9617c9a6880b","permalink":"https://haipinglu.github.io/publication/ge-2021-mixed/","publishdate":"2021-12-29T13:50:26.621126Z","relpermalink":"/publication/ge-2021-mixed/","section":"publication","summary":"Spectral clustering (SC) is a popular approach for gaining insights from complex networks. Conventional SC focuses on second-order structures (e.g. edges) without direct consideration of higher-order structures (e.g. triangles). This has motivated SC extensions that directly consider higher-order structures. However, both approaches are limited to considering a single order. To address this issue, this paper proposes a novel Mixed-Order Spectral Clustering (MOSC) framework to model both second-order and third-order structures simultaneously. To model mixed-order structures, we propose two new methods based on Graph Laplacian (GL) and Random Walks (RW). MOSC-GL combines edge and triangle adjacency matrices, with theoretical performance guarantee. MOSC-RW combines first-order and second-order random walks for a probabilistic interpretation. Moreover, we design mixed-order cut criteria to enable existing SC methods to preserve mixed-order structures, and develop new mixed-order evaluation metrics for structure-level evaluation. Experiments on community detection and superpixel segmentation show (1) the superior performance of the MOSC methods over existing SC methods, (2) enhanced performance of conventional SC due to mixed-order cut criteria, and (3) new insights of output clusters offered by the mixed-order evaluation metrics.","tags":[],"title":"Mixed-order spectral clustering for complex networks","type":"publication"},{"authors":["Yan Ge","Haiping Lu"],"categories":null,"content":"Spectral clustering (SC) is a popular approach for gaining insights from complex networks. Conventional SC focuses on second-order structures (e.g. edges) without direct consideration of higher-order structures (e.g. triangles). This has motivated SC extensions that directly consider higher-order structures. However, both approaches are limited to considering a single order.\nTo address this issue, we propose a novel Mixed-Order Spectral Clustering (MOSC) framework to model both second-order and third-order structures simultaneously. To model mixed-order structures, we propose two new methods based on Graph Laplacian (GL) and Random Walks (RW). MOSC-GL combines edge and triangle adjacency matrices, with theoretical performance guarantee. MOSC-RW combines first-order and second-order random walks for a probabilistic interpretation. Moreover, we design mixed-order cut criteria to enable existing SC methods to preserve mixed-order structures, and develop new mixed-order evaluation metrics for structure-level evaluation. Experiments on community detection and superpixel segmentation show (1) the superior performance of the MOSC methods over existing SC methods, (2) enhanced performance of conventional SC due to mixed-order cut criteria, and (3) new insights of output clusters offered by the mixed-order evaluation metrics.\n","date":1630454400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630454400,"objectID":"c7f9b8d3750e98f3c7d5921f2eb18aea","permalink":"https://haipinglu.github.io/project/mixed-order-clustering/","publishdate":"2021-09-01T00:00:00Z","relpermalink":"/project/mixed-order-clustering/","section":"project","summary":"Model both second-order and third-order structures simultaneously for complex networks","tags":["Graph Machine Learning","Interpretable Machine Learning"],"title":"Mixed-order spectral clustering for networks","type":"project"},{"authors":["Xianyuan Liu","Shuo Zhou","Tao Lei","Haiping Lu"],"categories":[],"content":"","date":1627776e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785834,"objectID":"cf8a2408d27f5d48dd4b58d34d316fff","permalink":"https://haipinglu.github.io/publication/liu-2021-channel/","publishdate":"2021-12-29T13:50:33.087274Z","relpermalink":"/publication/liu-2021-channel/","section":"publication","summary":"Unsupervised Domain Adaptation (UDA) can transfer knowledge from labeled source data to unlabeled target data of the same categories. However, UDA for first-person action recognition is an under-explored problem, with lack of datasets and limited consideration of first-person video characteristics. This paper focuses on addressing this problem. Firstly, we propose two small-scale first-person video domain adaptation datasets: ADLsmall and GTEA-KITCHEN. Secondly, we introduce channel-temporal attention blocks to capture the channel-wise and temporal-wise relationships and model their inter-dependencies important to first-person vision. Finally, we propose a Channel-Temporal Attention Network (CTAN) to integrate these blocks into existing architectures. CTAN outperforms baselines on the two proposed datasets and one existing dataset EPICcvpr20","tags":[],"title":"Channel-temporal attention for first-person video domain adaptation","type":"publication"},{"authors":["Hao Xu","Shengqi Sang","Herbert Yao","Alexandra I Herghelegiu","Haiping Lu","Laurence Yang"],"categories":[],"content":"","date":1625097600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785833,"objectID":"50821f8f7c12e8faecc74104e78c3db8","permalink":"https://haipinglu.github.io/publication/xu-2021-aprile/","publishdate":"2021-12-29T13:50:32.006143Z","relpermalink":"/publication/xu-2021-aprile/","section":"publication","summary":"With the majority of people 65 and over taking two or more medicines (polypharmacy), managing the side effects associated with polypharmacy is a global challenge. Explainable Artificial Intelligence (XAI) is necessary to reliably design safe polypharmacy. Here, we develop APRILE: a predictor-explainer framework based on graph neural networks to explore the molecular mechanisms underlying polypharmacy side effects by explaining predictions made by the predictors. For a side effect and its associated drug pair, or a set of side effects and their drug pairs, APRILE gives a set of proteins (drug targets or non-targets) and Gene Ontology (GO) items as the explanation. Using APRILE, we generate such explanations for 843,318 (learned) + 93,966 (novel) side effect‚Äìdrug pair events, spanning 861 side effects (472 diseases, 485 symptoms and 9 mental disorders) and 20 disease categories. We show that our two new metrics, pharmacogenomic information utilization and protein-protein interaction information utilization, provide quantitative estimates of mechanism complexity. Explanations were significantly consistent with state of the art disease-gene associations for 232/239 (97%) side effects. Further, APRILE generated new insights into molecular mechanisms of four diverse categories of ADRs: infection, metabolic diseases, gastrointestinal diseases, and mental disorders, including paradoxical side effects. We demonstrate the viability of discovering polypharmacy side effect mechanisms by learning from an AI model trained on massive biomedical data. Consequently, it facilitates wider and more reliable use of AI in healthcare.","tags":[],"title":"APRILE: Exploring the molecular mechanisms of drug side effects with explainable graph neural networks","type":"publication"},{"authors":["Yang Zhou","Haiping Lu","Yiu-Ming Cheung"],"categories":[],"content":"","date":1625097600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785815,"objectID":"436f0c51c901ae16443f32c842553b6b","permalink":"https://haipinglu.github.io/publication/zhou-2019-probabilistic/","publishdate":"2021-12-29T13:50:15.185026Z","relpermalink":"/publication/zhou-2019-probabilistic/","section":"publication","summary":"Subspace learning for tensors attracts increasing interest in recent years, leading to the development of multilinear extensions of principal component analysis (PCA) and probabilistic PCA (PPCA). Existing multilinear PPCAs are based on the Tucker or CANDECOMP/PARAFAC (CP) models. Although both kinds of multilinear PPCAs have shown their effectiveness in dealing with tensors, they also have their own limitations. Tucker-based multilinear PPCAs have a restrictive subspace representation and suffer from rotational ambiguity, while CP-based ones are more prone to overfitting. To address these problems, we propose probabilistic rank-one tensor analysis (PROTA), a CP-based multilinear PPCA. PROTA has a more flexible subspace representation than Tucker-based PPCAs, and avoids rotational ambiguity. To alleviate overfitting for CP-based PPCAs, we propose two simple and effective regularization strategies, named as concurrent regularizations (CRs). By adjusting the noise variance or the moments of latent features, our strategies concurrently and coherently penalize the entire subspace. This relaxes unnecessary scale restrictions and gains more flexibility in regularizing CP-based PPCAs. To take full advantage of the probabilistic framework, we further propose a Bayesian treatment of PROTA, which achieves both automatic feature determination and robustness against overfitting. Experiments on synthetic and real-world datasets demonstrate the superiority of PROTA in subspace estimation and classification, as well as the effectiveness of CRs in alleviating overfitting.","tags":[],"title":"Probabilistic rank-one tensor analysis with concurrent regularizations","type":"publication"},{"authors":["Raivo Koot","Haiping Lu"],"categories":[],"content":"","date":1625097600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785831,"objectID":"3e4eabbe3c6704279715d5a3652f6cff","permalink":"https://haipinglu.github.io/publication/koot-2021-videolightformer/","publishdate":"2021-12-29T13:50:30.833598Z","relpermalink":"/publication/koot-2021-videolightformer/","section":"publication","summary":"Efficient video action recognition remains a challenging problem. One large model after another takes the place of the state-of-the-art on the Kinetics dataset, but real-world efficiency evaluations are often lacking. In this work, we fill this gap and investigate the use of transformers for efficient action recognition. We propose a novel, lightweight action recognition architecture, VideoLightFormer. In a factorized fashion, we carefully extend the 2D convolutional Temporal Segment Network with transformers, while maintaining spatial and temporal video structure throughout the entire model. Existing methods often resort to one of the two extremes, where they either apply huge transformers to video features, or minimal transformers on highly pooled video features. Our method differs from them by keeping the transformer models small, but leveraging full spatiotemporal feature structure. We evaluate VideoLightFormer in a high-efficiency setting on the temporally-demanding EPIC-KITCHENS-100 and Something-Something-V2 (SSV2) datasets and find that it achieves a better mix of efficiency and accuracy than existing state-of-the-art models, apart from the Temporal Shift Module on SSV2.","tags":[],"title":"VideoLightFormer: Lightweight action recognition using transformers","type":"publication"},{"authors":["Mwiza Kunda","Shuo Zhou","Gaolang Gong","Haiping Lu"],"categories":null,"content":"Autism spectrum disorder (ASD) has no objective diagnosis method despite having a high prevalence. Machine learning has been widely used to develop classification models for ASD using neuroimaging data. Recently, studies have shifted towards using large multi-site neuroimaging datasets to boost the clinical applicability and statistical power of results. However, the classification performance is hindered by the heterogeneous nature of agglomerative datasets.\nIn this project, we propose new methods for multi-site autism classification using the Autism Brain Imaging Data Exchange (ABIDE) dataset. We firstly propose a new second-order measure of functional connectivity (FC) named as Tangent Pearson embedding to extract better features for classification. Then we assess the statistical dependence between acquisition sites and FC features, and apply a domain adaptation approach to minimise the site dependence of FC features to improve classification. Our analysis shows that 1) statistical dependence between site and FC features is statistically significant at the 5% level, and 2) extracting second-order features from neuroimaging data and minimising their site dependence can improve over state-of-the-art classification results on the ABIDE dataset, achieving a classification accuracy of 73%.\n","date":1622592e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622592e3,"objectID":"073281b388333b4a62b4a395ee018f52","permalink":"https://haipinglu.github.io/project/brain-fmri-multisite/","publishdate":"2021-06-02T00:00:00Z","relpermalink":"/project/brain-fmri-multisite/","section":"project","summary":"Classify autism across multiple sites via site-dependence minimisation \u0026 second-order functional connectivity","tags":["Multimodal AI","AI4Health","Medical Imaging","Interpretable Machine Learning","Selected"],"title":"Multisite brain fMRI classification","type":"project"},{"authors":["Haiping Lu","Xianyuan Liu","Robert Turner","Peizhen Bai","Raivo E Koot","Shuo Zhou","Mustafa Chasmai","Lawrence Schobs"],"categories":[],"content":"","date":1622505600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785830,"objectID":"0452a77b64e54ca84171e66e8ee9f757","permalink":"https://haipinglu.github.io/publication/lu-2021-pykale/","publishdate":"2021-12-29T13:50:29.903064Z","relpermalink":"/publication/lu-2021-pykale/","section":"publication","summary":"Machine learning is a general-purpose technology holding promises for many interdisciplinary research problems. However, significant barriers exist in crossing disciplinary boundaries when most machine learning tools are developed in different areas separately. We present Pykale - a Python library for knowledge-aware machine learning on graphs, images, texts, and videos to enable and accelerate interdisciplinary research. We formulate new green machine learning guidelines based on standard software engineering practices and propose a novel pipeline-based application programming interface (API). PyKale focuses on leveraging knowledge from multiple sources for accurate and interpretable prediction, thus supporting multimodal learning and transfer learning (particularly domain adaptation) with latest deep learning and dimensionality reduction models. We build PyKale on PyTorch and leverage the rich PyTorch ecosystem. Our pipeline-based API design enforces standardization and minimalism, embracing green machine learning concepts via reducing repetitions and redundancy, reusing existing resources, and recycling learning models across areas. We demonstrate its interdisciplinary nature via examples in bioinformatics, knowledge graph, image/video recognition, and medical imaging.","tags":[],"title":"PyKale: Knowledge-aware machine learning from multiple sources in python","type":"publication"},{"authors":["Markus D. Schirmer","Archana Venkataraman","Islem Rekik","Minjeong Kim","Stewart H. Mostofsky","Mary Beth Nebel","Keri S. Rosch","Karen E Seymour","Deana Crocetti","Hassna Irzan","Michael H√ºtel","S√©bastien Ourselin","Neil Marlow","Andrew Melbourne","Egor Levchenko","Shuo Zhou","Mwiza Kunda","Haiping Lu","Nicha C. Dvornek","Juntang Zhuang","Gideon Pinto","Sandip Samal","Jorge L. Bernal-Rusiel","Rudolph Pienaar","Ai Wern Chung"],"categories":[],"content":"","date":1619827200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785821,"objectID":"6b4f684671774ada49a6422c0a97f38f","permalink":"https://haipinglu.github.io/publication/schirmer-2021-neuropsychiatric/","publishdate":"2021-12-29T13:50:20.453064Z","relpermalink":"/publication/schirmer-2021-neuropsychiatric/","section":"publication","summary":"Large, open-source datasets, such as the Human Connectome Project and the Autism Brain Imaging Data Exchange, have spurred the development of new and increasingly powerful machine learning approaches for brain connectomics. However, one key question remains: are we capturing biologically relevant and generalizable information about the brain, or are we simply overfitting to the data? To answer this, we organized a scientific challenge, the Connectomics in NeuroImaging Transfer Learning Challenge (CNI-TLC), held in conjunction with MICCAI 2019. CNI-TLC included two classification tasks: (1) diagnosis of Attention-Deficit/Hyperactivity Disorder (ADHD) within a pre-adolescent cohort; and (2) transference of the ADHD model to a related cohort of Autism Spectrum Disorder (ASD) patients with an ADHD comorbidity. In total, 240 resting-state fMRI (rsfMRI) time series averaged according to three standard parcellation atlases, along with clinical diagnosis, were released for training and validation (120 neurotypical controls and 120 ADHD). We also provided Challenge participants with demographic information of age, sex, IQ, and handedness. The second set of 100 subjects (50 neurotypical controls, 25 ADHD, and 25 ASD with ADHD comorbidity) was used for testing. Classification methodologies were submitted in a standardized format as containerized Docker images through ChRIS, an open-source image analysis platform. Utilizing an inclusive approach, we ranked the methods based on 16 metrics: accuracy, area under the curve, F1-score, false discovery rate, false negative rate, false omission rate, false positive rate, geometric mean, informedness, markedness, Matthew‚Äôs correlation coefficient, negative predictive value, optimized precision, precision, sensitivity, and specificity. The final rank was calculated using the rank product for each participant across all measures. Furthermore, we assessed the calibration curves of each methodology. Five participants submitted their method for evaluation, with one outperforming all other methods in both ADHD and ASD classification. However, further improvements are still needed to reach the clinical translation of functional connectomics. We have kept the CNI-TLC open as a publicly available resource for developing and validating new classification methodologies in the field of connectomics.","tags":[],"title":"Neuropsychiatric disease classification using functional connectomics - results of the connectomics in neuroimaging transfer learning challenge","type":"publication"},{"authors":["Lawrence Schobs","Shuo Zhou","Marcella Cogliano","Andrew J Swift","Haiping Lu"],"categories":[],"content":"","date":1617235200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785826,"objectID":"4a9ab1ab44a81d58e7976e096a96397f","permalink":"https://haipinglu.github.io/publication/schobs-2021-confidence/","publishdate":"2021-12-29T13:50:25.824328Z","relpermalink":"/publication/schobs-2021-confidence/","section":"publication","summary":"Landmark localisation in medical imaging has achieved great success using deep encoder-decoder style networks to regress heatmap images centered around the target landmarks. However, these networks are large and computationally expensive. Moreover, their clinical use often requires human interaction, opening the door for manual correction of low confidence predictions. We propose PHD-Net: a lightweight, multi-task Patch-based network combining Heatmap and Displacement regression. We design a simple Candidate Smoothing strategy to fuse its two-task outputs, generating the final prediction with quantified confidence. We evaluate PHD-Net on hundreds of Short Axis and Four Chamber cardiac MRIs, showing promising results.","tags":[],"title":"Confidence-quantifying landmark localisation for cardiac MRI","type":"publication"},{"authors":["Krit Dwivedi","Michael Sharkey","Robin Condliffe","Johanna Uthoff","Samer Alabed","Peter Metherall","Haiping Lu","Jim M Wild","Eric A Hoffman","Andrew Swift","David Kiely"],"categories":[],"content":"","date":1617235200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785828,"objectID":"14dbaef5590f1f3a4b388ec0867d1cd5","permalink":"https://haipinglu.github.io/publication/dwivedi-2021-pulmonary/","publishdate":"2021-12-29T13:50:27.763634Z","relpermalink":"/publication/dwivedi-2021-pulmonary/","section":"publication","summary":"Accurate phenotyping of patients with pulmonary hypertension (PH) is an integral part of informing disease classification, treatment, and prognosis. The impact of lung disease on PH outcomes and response to treatment remains a challenging area with limited progress. Imaging with computed tomography (CT) plays an important role in patients with suspected PH when assessing for parenchymal lung disease, however, current assessments are limited by their semi-qualitative nature. Quantitative chest-CT (QCT) allows numerical quantification of lung parenchymal disease beyond subjective visual assessment. This has facilitated advances in radiological assessment and clinical correlation of a range of lung diseases including emphysema, interstitial lung disease, and coronavirus disease 2019 (COVID-19). Artificial Intelligence approaches have the potential to facilitate rapid quantitative assessments. Benefits of cross-sectional imaging include ease and speed of scan acquisition, repeatability and the potential for novel insights beyond visual assessment alone. Potential clinical benefits include improved phenotyping and prediction of treatment response and survival. Artificial intelligence approaches also have the potential to aid more focused study of pulmonary arterial hypertension (PAH) therapies by identifying more homogeneous subgroups of patients with lung disease. This state-of-the-art review summarizes recent QCT developments and potential applications in patients with PH with a focus on lung disease.","tags":[],"title":"Pulmonary hypertension in association with lung disease: quantitative CT and artificial intelligence to the rescue? state-of-the-art review","type":"publication"},{"authors":["Andrew Swift","Haiping Lu","Johanna Uthoff","Pankaj Garg","Marcella Cogliano","Jonathan Taylor","Peter Metherall","Shuo Zhou","Christopher S Johns","Samer Alabed","Robin Condliffe","Allan Lawrie","Jim Wild","David Kiely"],"categories":[],"content":"","date":1612137600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785819,"objectID":"326ab1b2d23726ccd71c50b841a21eca","permalink":"https://haipinglu.github.io/publication/swift-2021-machine/","publishdate":"2021-12-29T13:50:17.949363Z","relpermalink":"/publication/swift-2021-machine/","section":"publication","summary":"Aims: Pulmonary arterial hypertension (PAH) is a progressive condition with high mortality. Quantitative cardiovascular magnetic resonance (CMR) imaging metrics in PAH target individual cardiac structures and have diagnostic and prognostic utility but are challenging to acquire. The primary aim of this study was to develop and test a tensor-based machine learning approach to holistically identify diagnostic features in PAH using CMR, and secondarily, visualize and interpret key discriminative features associated with PAH. Methods and results: Consecutive treatment naive patients with PAH or no evidence of pulmonary hypertension (PH), undergoing CMR and right heart catheterization within 48‚Äâh, were identified from the ASPIRE registry. A tensor-based machine learning approach, multilinear subspace learning, was developed and the diagnostic accuracy of this approach was compared with standard CMR measurements. Two hundred and twenty patients were identified: 150 with PAH and 70 with no PH. The diagnostic accuracy of the approach was high as assessed by area under the curve at receiver operating characteristic analysis (P‚Äâ","tags":[],"title":"A machine learning cardiac magnetic resonance approach to extract disease features and automate pulmonary arterial hypertension diagnosis","type":"publication"},{"authors":["admin","Âê≥ÊÅ©ÈÅî"],"categories":["Demo","ÊïôÁ®ã"],"content":"Overview  The Wowchemy website builder for Hugo, along with its starter templates, is designed for professional creators, educators, and teams/organizations - although it can be used to create any kind of site The template can be modified and customised to suit your needs. It\u0026rsquo;s a good platform for anyone looking to take control of their data and online identity whilst having the convenience to start off with a no-code solution (write in Markdown and customize with YAML parameters) and having flexibility to later add even deeper personalization with HTML and CSS You can work with all your favourite tools and apps with hundreds of plugins and integrations to speed up your workflows, interact with your readers, and much more    The template is mobile first with a responsive design to ensure that your site looks stunning on every device.  Get Started  üëâ Create a new site üìö Personalize your site üí¨ Chat with the Wowchemy community or Hugo community üê¶ Twitter: @wowchemy @GeorgeCushen #MadeWithWowchemy üí° Request a feature or report a bug for Wowchemy ‚¨ÜÔ∏è Updating Wowchemy? View the Update Tutorial and Release Notes  Crowd-funded open-source software To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.\n‚ù§Ô∏è Click here to become a sponsor and help support Wowchemy\u0026rsquo;s future ‚ù§Ô∏è As a token of appreciation for sponsoring, you can unlock these awesome rewards and extra features ü¶Ñ‚ú®\nEcosystem  Hugo Academic CLI: Automatically import publications from BibTeX  Inspiration Check out the latest demo of what you\u0026rsquo;ll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\nFeatures  Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 34+ language packs including English, ‰∏≠Êñá, and Portugu√™s Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files.  Themes Wowchemy and its templates come with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\nChoose a stunning theme and font for your site. Themes are fully customizable.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"https://haipinglu.github.io/post/getting-started/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"Welcome üëã We know that first impressions are important, so we've populated your new site with some initial content to help you get familiar with everything in no time.","tags":["Academic","ÂºÄÊ∫ê"],"title":"Welcome to Wowchemy, the website builder for Hugo","type":"post"},{"authors":["Li Zhang","Yan Ge","Haiping Lu"],"categories":[],"content":"","date":1606780800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785829,"objectID":"bfa33d080506a68f29e8ce61503ad05e","permalink":"https://haipinglu.github.io/publication/zhang-2020-hop/","publishdate":"2021-12-29T13:50:28.691243Z","relpermalink":"/publication/zhang-2020-hop/","section":"publication","summary":"Graph Neural Networks (GNNs) are widely used in graph representation learning. However, most GNN methods are designed for either homogeneous or heterogeneous graphs. In this paper, we propose a new model, Hop-Hop Relation-aware Graph Neural Network (HHR-GNN), to unify representation learning for these two types of graphs. HHR-GNN learns a personalized receptive field for each node by leveraging knowledge graph embedding to learn relation scores between the central node's representations at different hops. In neighborhood aggregation, our model simultaneously allows for hop-aware projection and aggregation. This mechanism enables the central node to learn a hop-wise neighborhood mixing that can be applied to both homogeneous and heterogeneous graphs. Experimental results on five benchmarks show the competitive performance of our model compared to state-of-the-art GNNs, e.g., up to 13K faster in terms of time cost per training epoch on large heterogeneous graphs.","tags":[],"title":"Hop-hop relation-aware graph neural networks","type":"publication"},{"authors":["Yan Ge","Jun Ma","Li Zhang","Haiping Lu"],"categories":[],"content":"","date":1606780800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785825,"objectID":"d15050386ad5468c5f72cc497b5aab7f","permalink":"https://haipinglu.github.io/publication/ge-2020-unifying/","publishdate":"2021-12-29T13:50:24.823188Z","relpermalink":"/publication/ge-2020-unifying/","section":"publication","summary":"Higher-order proximity (HOP) is fundamental for most network embedding methods due to its significant effects on the quality of node embedding and performance on downstream network analysis tasks. Most existing HOP definitions are based on either homophily to place close and highly interconnected nodes tightly in embedding space or heterophily to place distant but structurally similar nodes together after embedding. In real-world networks, both can co-exist, and thus considering only one could limit the prediction performance and interpretability. However, there is no general and universal solution that takes both into consideration. In this paper, we propose such a simple yet powerful framework called homophily and heterophliy preserving network transformation (H2NT) to capture HOP that flexibly unifies homophily and heterophily. Specifically, H2NT utilises motif representations to transform a network into a new network with a hybrid assumption via micro-level and macro-level walk paths. H2NT can be used as an enhancer to be integrated with any existing network embedding methods without requiring any changes to latter methods. Because H2NT can sparsify networks with motif structures, it can also improve the computational efficiency of existing network embedding methods when integrated. We conduct experiments on node classification, structural role classification and motif prediction to show the superior prediction performance and computational efficiency over state-of-the-art methods. In particular, DeepWalk-based H2 NT achieves 24% improvement in terms of precision on motif prediction, while reducing 46% computational time compared to the original DeepWalk.","tags":[],"title":"Unifying homophily and heterophily network transformation via motifs","type":"publication"},{"authors":["Samer Alabed","Shuo Zhou","Johanna Uthoff","Andrew Swift","Haiping Lu"],"categories":null,"content":"This project is a Wellcome Trust Innovator Awards: Digital Technologies.\nCardiovascular diseases account for 26% of deaths in the UK. Current clinical imaging assessments rely on manual or semi-automated measurements. Emerging approaches focus on individual parts of the heart. We have developed the first tensor-based machine learning approach that holistically assesses the heart and surrounding structures on cardiovascular magnetic resonance imaging (CMRI) scans. We will develop this approach into a tool that can identify patients who respond to treatment or who will die early. Key advantages are rapid holistic assessment, minimal human error and full transparency with direct visualisation of features for the disease. We will assemble a large cohort of CMRI scans from 5, 000 patients with pulmonary hypertension, a severe condition affecting the heart, and assess the ability to predict treatment response and likelihood of early death. This tool will revolutionise disease assessment, and improve treatment delivery and patient care.\n","date":1604188800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604188800,"objectID":"8fd1d4d46a203f18d638695dc3def8d5","permalink":"https://haipinglu.github.io/project-removed/ml-assess-cmr/","publishdate":"2020-11-01T00:00:00Z","relpermalink":"/project-removed/ml-assess-cmr/","section":"project-removed","summary":"Interpretable machine learning to improve prognostic and treatment response assessment on cardiac MRI","tags":["Interpretable Machine Learning","Medical Imaging"],"title":"Interpretable ML for Cardiac MRI","type":"project-removed"},{"authors":["Li Zhang","Haiping Lu"],"categories":[],"content":"","date":1601510400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785823,"objectID":"d6736944b4498812f064b2502dcb00ea","permalink":"https://haipinglu.github.io/publication/zhang-2020-feature/","publishdate":"2021-12-29T13:50:22.758767Z","relpermalink":"/publication/zhang-2020-feature/","section":"publication","summary":"Neighborhood aggregation is a key step in Graph Convolutional Networks (GCNs) for graph representation learning. Two commonly used aggregators, sum and mean, are designed with the homophily assumption that connected nodes are likely to share the same label. However, real-world graphs are noisy and adjacent nodes do not necessarily imply similarity.Learnable aggregators are proposed in Graph Attention Network (GAT) and Learnable Graph Convolutional Layer (LGCL). However, GAT considers node importance but not the importance of different features. The convolution aggregator in LGCL considers feature importance but it can not directly operate on graphs due to the irregular connectivity and lack of orderliness. In this paper, we firstly unify the current learnable aggregators in a framework: Learnable Aggregator for GCN (LA-GCN) by introducing a shared auxiliary model that provides a customized schema in neighborhood aggregation. Under this framework, we propose a new model called LA-GCNMask consisting of a new aggregator function,mask aggregator. The auxiliary model learns a specific mask for each neighbor of a given node, allowing both node-level and feature-level attention. This mechanism learns to assign different importance to both nodes and features for prediction, which provides interpretable explanations for prediction and increases the model robustness. Experiments on seven graphs for node classification and graph classification tasks show that LA-GCNMask outperforms the state-of-the-art methods. Moreover, our aggregator can identify both the important nodes and node features simultaneously, which provides a quantified understanding of the relationship between input nodes and the prediction. We further conduct experiments on noisy graphs to evaluate the robustness of our model. Experiments show that LA-GCNMask consistently outperforms the state-of-the-art methods, with up to 15% improvements in terms of accuracy compared to the second best.","tags":[],"title":"A feature-importance-aware and robust aggregator for GCN","type":"publication"},{"authors":["Hao Xu","Shengqi Sang","Peizhen Bai","Laurence Yang","Haiping Lu"],"categories":[],"content":"","date":1601510400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785824,"objectID":"d19907e15a12090893ba80b00c483bd2","permalink":"https://haipinglu.github.io/publication/xu-2020-gripnet/","publishdate":"2021-12-29T13:50:23.970009Z","relpermalink":"/publication/xu-2020-gripnet/","section":"publication","summary":"Heterogeneous graph representation learning aims to learn low-dimensional vector representations of different types of entities and relations to empower downstream tasks. Existing methods either capture semantic relationships but indirectly leverage node/edge attributes in a complex way, or leverage node/edge attributes directly without taking semantic relationships into account. When involving multiple convolution operations, they also have poor scalability. To overcome these limitations, this paper proposes a flexible and efficient Graph information propagation Network (GripNet) framework. Specifically, we introduce a new supergraph data structure consisting of supervertices and superedges. A supervertex is a semantically-coherent subgraph. A superedge defines an information propagation path between two supervertices. GripNet learns new representations for the supervertex of interest by propagating information along the defined path using multiple layers. We construct multiple large-scale graphs and evaluate GripNet against competing methods to show its superiority in link prediction, node classification, and data integration.","tags":[],"title":"GripNet: Graph information propagation on supergraph for heterogeneous graphs","type":"publication"},{"authors":["Li Zhang","Haiping Lu"],"categories":null,"content":"Neighborhood aggregation is a key step in Graph Convolutional Networks (GCNs) for graph representation learning. Two commonly used aggregators, sum and mean, are designed with the homophily assumption that connected nodes are likely to share the same label. However, real-world graphs are noisy and adjacent nodes do not necessarily imply similarity.Learnable aggregators are proposed in Graph Attention Network (GAT) and Learnable Graph Convolutional Layer (LGCL). However, GAT considers node importance but not the importance of different features. The convolution aggregator in LGCL considers feature importance but it can not directly operate on graphs due to the irregular connectivity and lack of orderliness.\nIn this work, we firstly unify the current learnable aggregators in a framework: Learnable Aggregator for GCN (LA-GCN) by introducing a shared auxiliary model that provides a customized schema in neighborhood aggregation. Under this framework, we propose a new model called LA-GCNMask consisting of a new aggregator function,mask aggregator. The auxiliary model learns a specific mask for each neighbor of a given node, allowing both node-level and feature-level attention. This mechanism learns to assign different importance to both nodes and features for prediction, which provides interpretable explanations for prediction and increases the model robustness. Experiments on seven graphs for node classification and graph classification tasks show that LA-GCNMask outperforms the state-of-the-art methods. Moreover, our aggregator can identify both the important nodes and node features simultaneously, which provides a quantified understanding of the relationship between input nodes and the prediction. We further conduct experiments on noisy graphs to evaluate the robustness of our model. Experiments show that LA-GCNMask consistently outperforms the state-of-the-art methods, with up to 15% improvements in terms of accuracy compared to the second best.\n","date":1601510400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601510400,"objectID":"3a23c98b9357c7f60090fb5b7dc32a38","permalink":"https://haipinglu.github.io/project/learnable-gcn-aggregator/","publishdate":"2020-10-01T00:00:00Z","relpermalink":"/project/learnable-gcn-aggregator/","section":"project","summary":"Construct a feature-importance-aware and robust aggregator for graph convolutional networks","tags":["Graph Machine Learning","Interpretable Machine Learning"],"title":"Learnable GCN aggregator","type":"project"},{"authors":["Johanna Uthoff","Samer Alabed","Andrew Swift","Haiping Lu"],"categories":[],"content":"","date":1598918400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785822,"objectID":"5530e4a8d618fd918982cce0dc3d943f","permalink":"https://haipinglu.github.io/publication/uthoff-2020-geodesically/","publishdate":"2021-12-29T13:50:21.675123Z","relpermalink":"/publication/uthoff-2020-geodesically/","section":"publication","summary":"Cardiac magnetic resonance imaging (CMRI) provides non-invasive characterization of the heart and surrounding tissues. It is an important tool for the prognosis of pulmonary arterial hypertension (PAH), a disease with heterogeneous presentation that makes survival likelihood prediction a challenging task. In this paper, we propose a Geodesically Smooothed Tensor feature learning method (GST) that utilizes not only the heart but also its surrounding tissues to characterize disease severity for improving prognosis. Specifically, GST includes structures surrounding the heart by geodesic rings which were incrementally smoothed with Gaussian filters. This provides additive insight while modulating for patient positional differences for a subsequent tensor-based feature learning pipeline. We performed evaluation on Four Chamber and Short Axis CMRI from 150 individuals with confirmed PAH and 1-year mortality census (27 deceased, 123 alive). The proposed GST method improved AUC and Cox difference at 4-years post-imaging (Cox4YD) over the standardized measurement of right ventricular end systolic volume index (RVESVi: AUC: 0.58; Cox4YD: 0.18) on the Four Chamber protocol (AUC: 0.77; Cox4YD: 0.35). Only AUC was improved over RVESVi in the Short Axis scans (AUC: 0.77; Cox4YD: 0.16).","tags":[],"title":"Geodesically smoothed tensor features for pulmonary hypertension prognosis using the heart and surrounding tissues","type":"publication"},{"authors":["Mwiza Kunda","Shuo Zhou","Gaolang Gong","Haiping Lu"],"categories":[],"content":"","date":1580515200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785820,"objectID":"c55473fa2e5923c9cc3d27a901626e88","permalink":"https://haipinglu.github.io/publication/kunda-2020-improving/","publishdate":"2021-12-29T13:50:19.270245Z","relpermalink":"/publication/kunda-2020-improving/","section":"publication","summary":"Autism spectrum disorder (ASD) has no objective diagnosis method despite having a high prevalence. Machine learning has been widely used to develop classification models for ASD using neuroimaging data. Recently, studies have shifted towards using large multi-site neuroimaging datasets to boost the clinical applicability and statistical power of results. However, the classification performance is hindered by the heterogeneous nature of agglomerative datasets. In this paper, we propose new methods for multi-site autism classification using the Autism Brain Imaging Data Exchange (ABIDE) dataset. We firstly propose a new second-order measure of functional connectivity (FC) named as Tangent Pearson embedding to extract better features for classification. Then we assess the statistical dependence between acquisition sites and FC features, and apply a domain adaptation approach to minimise the site dependence of FC features to improve classification. Our analysis shows that 1) statistical dependence between site and FC features is statistically significant at the 5% level, and 2) extracting second-order features from neuroimaging data and minimising their site dependence can improve over state-of-the-art classification results on the ABIDE dataset, achieving a classification accuracy of 73%.","tags":[],"title":"Improving multi-site autism classification based on site-dependence minimisation and second-order functional connectivity","type":"publication"},{"authors":["Shuo Zhou","Wenwen Li","Christopher Cox","Haiping Lu"],"categories":[],"content":"","date":1580515200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785817,"objectID":"684e621e31fec71dfca212370cf663cb","permalink":"https://haipinglu.github.io/publication/zhou-2020-side/","publishdate":"2021-12-29T13:50:17.05872Z","relpermalink":"/publication/zhou-2020-side/","section":"publication","summary":"The increasing of public neuroimaging datasets opens a door to analyzing homogeneous human brain conditions across datasets by transfer learning (TL). However, neuroimaging data are high-dimensional, noisy, and with small sample sizes. It is challenging to learn a robust model for data across different cognitive experiments and subjects. A recent TL approach minimizes domain dependence to learn common cross-domain features, via the Hilbert-Schmidt Independence Criterion (HSIC). Inspired by this approach and the multi-source TL theory, we propose a Side Information Dependence Regularization (SIDeR) learning framework for TL in brain condition decoding. Specifically, SIDeR simultaneously minimizes the empirical risk and the statistical dependence on the domain side information, to reduce the theoretical generalization error bound. We construct 17 brain decoding TL tasks using public neuroimaging data for evaluation. Comprehensive experiments validate the superiority of SIDeR over ten competing methods, particularly an average improvement of 15.6% on the TL tasks with multi-source experiments.","tags":[],"title":"Side information dependence as a regularizer for analyzing human brain conditions across cognitive experiments","type":"publication"},{"authors":["Hao Xu","Shengqi Sang","Haiping Lu"],"categories":[],"content":"","date":1575158400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785816,"objectID":"08110bec2687ac6149f201f735c75ee5","permalink":"https://haipinglu.github.io/publication/xu-2020-tri/","publishdate":"2021-12-29T13:50:16.045253Z","relpermalink":"/publication/xu-2020-tri/","section":"publication","summary":"The use of drug combinations often leads to polypharmacy side effects (POSE). A recent method formulates POSE prediction as a link prediction problem on a graph of drugs and proteins, and solves it with Graph Convolutional Networks (GCNs). However, due to the complex relationships in POSE, this method has high computational cost and memory demand. This paper proposes a flexible Tri-graph Information Propagation (TIP) model that operates on three subgraphs to learn representations progressively by propagation from protein-protein graph to drug-drug graph via protein-drug graph. Experiments show that TIP improves accuracy by 7%+, time efficiency by 83√ó, and space efficiency by 3√ó.","tags":[],"title":"Tri-graph information propagation for polypharmacy side effect prediction","type":"publication"},{"authors":["Shuo Zhou","Christopher R Cox","Haiping Lu"],"categories":[],"content":"","date":1569888e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785810,"objectID":"7ab13a3f50fa86317432efa9462bcd19","permalink":"https://haipinglu.github.io/publication/zhou-2019-improving/","publishdate":"2021-12-29T13:50:09.013946Z","relpermalink":"/publication/zhou-2019-improving/","section":"publication","summary":"In neural decoding, there has been a growing interest in machine learning on functional magnetic resonance imaging (fMRI). However, the size discrepancy between the whole-brain feature space and the training set poses serious challenges. Simply increasing the number of training examples is infeasible and costly. In this paper, we propose a domain adaptation framework for whole-brain fMRI (DawfMRI) to improve whole-brain neural decoding on target data leveraging source data. DawfMRI consists of two steps: (1) source and target feature adaptation, and (2) source and target classifier adaptation. We evaluate its four possible variations, using a collection of fMRI datasets from OpenfMRI. The results demonstrated that appropriate choices of source domain can help improve neural decoding accuracy for challenging classification tasks. The best-case improvement is   10.47%  (from   77.26%  to   87.73% ). Moreover, visualising and interpreting voxel weights revealed that the adaptation can provide additional insights into neural decoding.","tags":[],"title":"Improving whole-brain neural decoding of fMRI with domain adaptation","type":"publication"},{"authors":["Wenwen Li","Jian Lou","Shuo Zhou","Haiping Lu"],"categories":[],"content":"","date":1569888e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785812,"objectID":"c14150f1caec4fdfaa3ad375d29e0b0b","permalink":"https://haipinglu.github.io/publication/li-2019-sturm/","publishdate":"2021-12-29T13:50:11.08281Z","relpermalink":"/publication/li-2019-sturm/","section":"publication","summary":"While functional magnetic resonance imaging (fMRI) is important for healthcare/neuroscience applications, it is challenging to classify or interpret due to its multi-dimensional structure, high dimensionality, and small number of samples available. Recent sparse multilinear regression methods based on tensor are emerging as promising solutions for fMRI. Particularly, the newly proposed tensor singular value decomposition (t-SVD) sheds light on new directions. In this work, we study t-SVD for sparse multilinear regression and propose a Sparse tubal-regularized multilinear regression (Sturm) method for fMRI. Specifically, the Sturm model performs multilinear regression with two regularization terms: a tubal tensor nuclear norm based on t-SVD and a standard   ‚Ñì1  norm. An optimization algorithm under the alternating direction method of multipliers framework is derived for solving the Sturm model. We then perform experiments on four classification problems, including both resting-state fMRI for disease diagnosis and task-based fMRI for neural decoding. The results show the superior performance of Sturm in classifying fMRI using just a small number of voxels.","tags":[],"title":"Sturm: Sparse tubal-regularized multilinear regression for fMRI","type":"publication"},{"authors":["Peizhen Bai","Yan Ge","Fangling Liu","Haiping Lu"],"categories":[],"content":"","date":1564617600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785814,"objectID":"32af02383969494ac31d773fbeddca41","permalink":"https://haipinglu.github.io/publication/bai-2019-joint/","publishdate":"2021-12-29T13:50:13.300015Z","relpermalink":"/publication/bai-2019-joint/","section":"publication","summary":"In recommender systems, the classical matrix factorization model for collaborative filtering only considers joint interactions between users and items. In contrast, context-aware recommender systems (CARS) use contexts to improve recommendation performance. Some early CARS models treat user, item and context equally, unable to capture contextual impact accurately. More recent models perform context operations on users and items separately, leading to ‚Äúdouble-counting‚Äù of contextual information. This paper proposes a new model, Joint Interaction with Context Operation (JICO), to integrate the joint interaction model with the context operation model, via two layers. The joint interaction layer models interactions between users and items via an interaction tensor. The context operation layer captures contextual information via a contextual operating tensor. We evaluate JICO on four datasets and conduct novel studies, including varying contextual influence and time split recommendation. JICO consistently outperforms competing methods, while providing many useful insights to assist further analysis.","tags":[],"title":"Joint interaction with context operation for collaborative filtering","type":"publication"},{"authors":["Qiquan Shi","Yiu-Ming Cheung","Qibin Zhao","Haiping Lu"],"categories":[],"content":"","date":1559347200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785811,"objectID":"6462fb1443ddf54d48420a81672a1c27","permalink":"https://haipinglu.github.io/publication/shi-2018-feature/","publishdate":"2021-12-29T13:50:10.102667Z","relpermalink":"/publication/shi-2018-feature/","section":"publication","summary":" Multidimensional data (i.e., tensors) with missing entries are common in practice. Extracting features from incomplete tensors is an important yet challenging problem in many fields such as machine learning, pattern recognition, and computer vision. Although the missing entries can be recovered by tensor completion techniques, these completion methods focus only on missing data estimation instead of effective feature extraction. To the best of our knowledge, the problem of feature extraction from incomplete tensors has yet to be well explored in the literature. In this paper, we therefore tackle this problem within the unsupervised learning environment. Specifically, we incorporate low-rank tensor decomposition with feature variance maximization (TDVM) in a unified framework. Based on orthogonal Tucker and CP decompositions, we design two TDVM methods, TDVM-Tucker and TDVM-CP, to learn low-dimensional features viewing the core tensors of the Tucker model as features and viewing the weight vectors of the CP model as features. TDVM explores the relationship among data samples via maximizing feature variance and simultaneously estimates the missing entries via low-rank Tucker/CP approximation, leading to informative features extracted directly from observed entries. Furthermore, we generalize the proposed methods by formulating a general model that incorporates feature regularization into low-rank tensor approximation. In addition, we develop a joint optimization scheme to solve the proposed methods by integrating the alternating direction method of multipliers with the block coordinate descent method. Finally, we evaluate our methods on six real-world image and video data sets under a newly designed multiblock missing setting. The extracted features are evaluated in face recognition, object/action classification, and face/gait clustering. Experimental results demonstrate the superior performance of the proposed methods compared with the state-of-the-art approaches.","tags":[],"title":"Feature extraction for incomplete data via low-rank tensor decomposition with feature regularization","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  **Two**  Three   A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://haipinglu.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Li Zhang","Heda Song","Haiping Lu"],"categories":[],"content":"","date":1541030400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785813,"objectID":"053c0f07d6d8214f8a8dc425596059b2","permalink":"https://haipinglu.github.io/publication/zhang-2018-graph/","publishdate":"2021-12-29T13:50:12.097449Z","relpermalink":"/publication/zhang-2018-graph/","section":"publication","summary":"Graph convolutional network (GCN) is an emerging neural network approach. It learns new representation of a node by aggregating feature vectors of all neighbors in the aggregation process without considering whether the neighbors or features are useful or not. Recent methods have improved solutions by sampling a fixed size set of neighbors, or assigning different weights to different neighbors in the aggregation process, but features within a feature vector are still treated equally in the aggregation process. In this paper, we introduce a new convolution operation on regular size feature maps constructed from features of a fixed node bandwidth via sampling to get the first-level node representation, which is then passed to a standard GCN to learn the second-level node representation. Experiments show that our method outperforms competing methods in semi-supervised node classification tasks. Furthermore, our method opens new doors for exploring new GCN architectures, particularly deeper GCN models.","tags":[],"title":"Graph node-feature convolution for representation learning","type":"publication"},{"authors":["Qiquan Shi","Haiping Lu","Yiu-Ming Cheung"],"categories":[],"content":"","date":1538352e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785808,"objectID":"9bbab7ffcff77a607c9be43b751a5d15","permalink":"https://haipinglu.github.io/publication/shi-2017-rank/","publishdate":"2021-12-29T13:50:08.029456Z","relpermalink":"/publication/shi-2017-rank/","section":"publication","summary":"Completing a matrix from a small subset of its entries, i.e., matrix completion is a challenging problem arising from many real-world applications, such as machine learning and computer vision. One popular approach to solve the matrix completion problem is based on low-rank decomposition/factorization. Low-rank matrix decomposition-based methods often require a prespecified rank, which is difficult to determine in practice. In this paper, we propose a novel low-rank decomposition-based matrix completion method with automatic rank estimation. Our method is based on rank-one approximation, where a matrix is represented as a weighted summation of a set of rank-one matrices. To automatically determine the rank of an incomplete matrix, we impose L1-norm regularization on the weight vector and simultaneously minimize the reconstruction error. After obtaining the rank, we further remove the L1-norm regularizer and refine recovery results. With a correctly estimated rank, we can obtain the optimal solution under certain conditions. Experimental results on both synthetic and real-world data demonstrate that the proposed method not only has good performance in rank estimation, but also achieves better recovery accuracy than competing methods.","tags":[],"title":"Rank-one matrix completion with automatic rank estimation via L1-norm regularization","type":"publication"},{"authors":["Qiquan Shi","Haiping Lu","Yiu-ming Cheung"],"categories":[],"content":"","date":1509494400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785807,"objectID":"d69a1b161784aa5550fdcbc4266616db","permalink":"https://haipinglu.github.io/publication/shi-2017-tensor/","publishdate":"2021-12-29T13:50:06.830742Z","relpermalink":"/publication/shi-2017-tensor/","section":"publication","summary":"Tensor completion (TC) is a challenging problem of recovering missing entries of a tensor from its partial observation. One main TC approach is based on CP/Tucker decomposition. However, this approach often requires the determination of a tensor rank a priori. This rank estimation problem is difficult in practice. Several Bayesian solutions have been proposed but they often under/over-estimate the tensor rank while being quite slow. To address this problem of rank estimation with missing entries, we view the weight vector of the orthogonal CP decomposition of a tensor to be analogous to the vector of singular values of a matrix. Subsequently, we define a new CP-based tensor nuclear norm as the $L_1$-norm of this weight vector. We then propose Tensor Rank Estimation based on $L_1$-regularized orthogonal CP decomposition (TREL1) for both CP-rank and Tucker-rank. Specifically, we incorporate a regularization with CP-based tensor nuclear norm when minimizing the reconstruction error in TC to automatically determine the rank of an incomplete tensor. Experimental results on both synthetic and real data show that: 1) Given sufficient observed entries, TREL1 can estimate the true rank (both CP-rank and Tucker-rank) of incomplete tensors well; 2) The rank estimated by TREL1 can consistently improve recovery accuracy of decomposition-based TC methods; 3) TREL1 is not sensitive to its parameters in general and more efficient than existing rank estimation methods.","tags":[],"title":"Tensor rank estimation and completion via CP-based nuclear norm","type":"publication"},{"authors":["Xiaofeng Xie","Zhu Liang Yu","Haiping Lu","Zhenghui Gu","Yuanqing Li"],"categories":[],"content":"","date":1496275200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785806,"objectID":"7e5e80b87c5e82acfd7534efd0000138","permalink":"https://haipinglu.github.io/publication/xie-2016-motor/","publishdate":"2021-12-29T13:50:05.935114Z","relpermalink":"/publication/xie-2016-motor/","section":"publication","summary":"In motor imagery brain-computer interfaces (BCIs), the symmetric positive-definite (SPD) covariance matrices of electroencephalogram (EEG) signals carry important discriminative information. In this paper, we intend to classify motor imagery EEG signals by exploiting the fact that the space of SPD matrices endowed with Riemannian distance is a high-dimensional Riemannian manifold. To alleviate the overfitting and heavy computation problems associated with conventional classification methods on high-dimensional manifold, we propose a framework for intrinsic sub-manifold learning from a high-dimensional Riemannian manifold. Considering a special case of SPD space, a simple yet efficient bilinear sub-manifold learning (BSML) algorithm is derived to learn the intrinsic sub-manifold by identifying a bilinear mapping that maximizes the preservation of the local geometry and global structure of the original manifold. Two BSML-based classification algorithms are further proposed to classify the data on a learned intrinsic sub-manifold. Experimental evaluation of the classification of EEG revealed that the BSML method extracts the intrinsic sub-manifold approximately 5√ó faster and with higher classification accuracy compared with competing algorithms. The BSML also exhibited strong robustness against a small training dataset, which often occurs in BCI studies.","tags":[],"title":"Motor imagery classification based on bilinear sub-manifold learning of symmetric positive-definite matrices","type":"publication"},{"authors":["Yang Zhou","Haiping Lu","Yiu-ming Cheung"],"categories":[],"content":"","date":1485907200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785804,"objectID":"7d9f64890bd7d15f16a6dd5480f9d43f","permalink":"https://haipinglu.github.io/publication/zhou-2017-bilinear/","publishdate":"2021-12-29T13:50:04.139014Z","relpermalink":"/publication/zhou-2017-bilinear/","section":"publication","summary":"Canonical Correlation Analysis (CCA) is a classical technique for two-view correlation analysis, while Probabilistic CCA (PCCA) provides a generative and more general viewpoint for this task. Recently, PCCA has been extended to bilinear cases for dealing with two-view matrices in order to preserve and exploit the matrix structures in PCCA. However, existing bilinear PCCAs impose restrictive model assumptions for matrix structure preservation, sacrificing generative correctness or model flexibility. To overcome these drawbacks, we propose BPCCA, a new bilinear extension of PCCA, by introducing a hybrid joint model. Our new model preserves matrix structures indirectly via hybrid vector-based and matrix-based concatenations. This enables BPCCA to gain more model flexibility in capturing two-view correlations and obtain close-form solutions in parameter estimation. Experimental results on two real-world applications demonstrate the superior performance of BPCCA over competing methods.","tags":[],"title":"Bilinear probabilistic canonical correlation analysis via hybrid concatenations","type":"publication"},{"authors":["Xiaonan Song","Haiping Lu"],"categories":[],"content":"","date":1485907200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785805,"objectID":"d1e737a88b86a8aed9bac5c9cd5935f9","permalink":"https://haipinglu.github.io/publication/song-2017-multilinear/","publishdate":"2021-12-29T13:50:05.064406Z","relpermalink":"/publication/song-2017-multilinear/","section":"publication","summary":"Embedded feature selection is effective when both prediction and interpretation are needed. The Lasso and its extensions are standard methods for selecting a subset of features while optimizing a prediction function. In this paper, we are interested in embedded feature selection for multidimensional data, wherein (1) there is no need to reshape the multidimensional data into vectors and (2) structural information from multiple dimensions are taken into account. Our main contribution is a new method called Regularized multilinear regression and selection (Remurs) for automatically selecting a subset of features while optimizing prediction for multidimensional data. Both nuclear norm and the ‚Ñì1-norm are carefully incorporated to derive a multi-block optimization algorithm with proved convergence. In particular, Remurs is motivated by fMRI analysis where the data are multidimensional and it is important to find the connections of raw brain voxels with functional activities. Experiments on synthetic and real data show the advantages of Remurs compared to Lasso, Elastic Net, and their multilinear extensions.","tags":[],"title":"Multilinear regression for embedded feature selection with application to fMRI analysis","type":"publication"},{"authors":["Liyan Song","Haiping Lu"],"categories":[],"content":"","date":1477958400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785804,"objectID":"e72357b7c7dacb1977c34889c2b18cc5","permalink":"https://haipinglu.github.io/publication/song-2016-ecoica/","publishdate":"2021-12-29T13:50:03.16377Z","relpermalink":"/publication/song-2016-ecoica/","section":"publication","summary":"Independent component analysis (ICA) is an important unsupervised learning method. Most popular ICA methods use kurtosis as a metric of non-Gaussianity to maximize, such as FastICA and JADE.However, their assumption of kurtosic sources may not always be satisfied in practice. For weak-kurtosic but skewed sources, kurtosis-based methods could fail while skewness-based methods seem more promising, where skewness is another non-Gaussianity metric measuring the non-symmetry of signals. Partly due to the common assumption of signal symmetry, skewness-based ICA has not been systematically studied in spite of some existing works. In this paper, we take a systematic approach to develop EcoICA, a new skewness-based ICA method for weak-kurtosic but skewed sources. Specifically, we design a new cumulant operator, define its eigenvalues and eigenvectors, reveal their connections with the ICA model to formulate the EcoICA problem, and use Jacobi method to solve it. Experiments on both synthetic and real data show the superior performance of EcoICA over existing kurtosis-based and skewness-based methods for skewed sources. In particular, EcoICA is less sensitive to sample size, noise, and outlier than other methods. Studies on face recognition further confirm the usefulness of EcoICA in classification.","tags":[],"title":"EcoICA: Skewness-based ICA via eigenvectors of cumulant operator","type":"publication"},{"authors":["Liyan Song","Haiping Lu"],"categories":[],"content":"","date":1477958400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785803,"objectID":"4630f5315b40b402d0d551fc00b6751c","permalink":"https://haipinglu.github.io/publication/song-2016-proper/","publishdate":"2021-12-29T13:50:02.373123Z","relpermalink":"/publication/song-2016-proper/","section":"publication","summary":"Independent Component Analysis (ICA) is a classical method for Blind Source Separation (BSS). In this paper, we are interested in ICA in the presence of noise, i.e., the noisy ICA problem. Pseudo-Euclidean Gradient Iteration (PEGI) is a recent cumulant-based method that defines a pseudo Euclidean inner product to replace a quasi-whitening step in Gaussian noise invariant ICA. However, PEGI has two major limitations: 1) the pseudo Euclidean inner product is improper because it violates the positive definiteness of inner product; 2) the inner product matrix is orthogonal by design but it has gross errors or imperfections due to sample-based estimation. This paper proposes a new cumulant-based ICA method named as PIMD to address these two problems. We first define a Proper Inner product (PI) with proved positive definiteness and then relax the centering preprocessing step to a mean displacement (MD) step. Both PI and MD aim to improve the orthogonality of inner product matrix and the recovery of independent components (ICs) in sample-based estimation. We adopt a gradient iteration step to find the ICs for PIMD. Experiments on both synthetic and real data show the respective effectiveness of PI and MD as well as the superiority of PIMD over competing ICA methods. Moreover, MD can improve the performance of other ICA methods as well.","tags":[],"title":"Proper inner product with mean displacement for gaussian noise invariant ICA","type":"publication"},{"authors":["Haiping Lu","Jianxin Wu","Yu Zhang"],"categories":[],"content":"","date":1467331200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785801,"objectID":"36e0d2d931138775b7f664dcca49bb7e","permalink":"https://haipinglu.github.io/publication/lu-2016-learning/","publishdate":"2021-12-29T13:50:00.060864Z","relpermalink":"/publication/lu-2016-learning/","section":"publication","summary":"For big, high-dimensional dense features, it is important to learn compact binary codes or compress them for greater memory efficiency. This paper proposes a Binarized Multilinear PCA (BMP) method for this problem with Free-Form Reshaping (FFR) of such features to higher-order tensors, lifting the structure-modelling restriction in traditional tensor models. The reshaped tensors are transformed to a subspace using multilinear PCA. Then, we unsupervisedly select features and supervisedly binarize them with a minimum-classification-error scheme to get compact binary codes. We evaluate BMP on two scene recognition datasets against state-of-the-art algorithms. The FFR works well in experiments. With the same number of compression parameters (model size), BMP has much higher classification accuracy. To achieve the same accuracy or compression ratio, BMP has an order of magnitude smaller number of compression parameters. Thus, BMP has great potential in memory-sensitive applications such as mobile computing and big data analytics.","tags":[],"title":"Learning compact binary codes from higher-order tensors via free-form reshaping and binarized multilinear PCA","type":"publication"},{"authors":["Yang Zhou","Haiping Lu"],"categories":[],"content":"","date":1467331200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785802,"objectID":"3738791c3a9d6587adb7de80267c720a","permalink":"https://haipinglu.github.io/publication/zhou-2016-probabilistic/","publishdate":"2021-12-29T13:50:01.282522Z","relpermalink":"/publication/zhou-2016-probabilistic/","section":"publication","summary":"As a classical subspace learning method, Probabilistic PCA (PPCA) has been extended to several bilinear variants for dealing with matrix observations. However, they are all based on the Tucker model, leading to a restricted subspace representation and the problem of rotational ambiguity. To address these problems, this paper proposes a bilinear PPCA method named as Probabilistic Rank-One Matrix Analysis (PROMA). PROMA is based on the CP model, which leads to a more flexible subspace representation and does not suffer from rotational ambiguity. For better generalization, concurrent regularization is introduced to regularize the whole matrix subspace, rather than column and row factors separately. Experiments on both synthetic and real-world data demonstrate the superiority of PROMA in subspace estimation and classification as well as the effectiveness of concurrent regularization in regularizing bilinear PPCAs.","tags":[],"title":"Probabilistic rank-one matrix analysis with concurrent regularization","type":"publication"},{"authors":["Xiaonan Song","Lingnan Meng","Qiquan Shi","Haiping Lu"],"categories":[],"content":"","date":1443657600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785798,"objectID":"79e74a7e703684affb04d56fe8f34bff","permalink":"https://haipinglu.github.io/publication/song-2015-learning/","publishdate":"2021-12-29T13:49:57.84563Z","relpermalink":"/publication/song-2015-learning/","section":"publication","summary":"This paper presents a novel tensor-based feature learning approach for whole-brain fMRI classification. Whole-brain fMRI data have high exploratory power, but they are challenging to deal with due to large numbers of voxels. A critical step for fMRI classification is dimensionality reduction, via feature selection or feature extraction. Most current approaches perform voxel selection based on feature selection methods. In contrast, feature extraction methods, such as principal component analysis (PCA), have limited usage on whole brain due to the small sample size problem and limited interpretability. To address these issues, we propose to directly extract features from natural tensor (rather than vector) representations of whole-brain fMRI using multilinear PCA (MPCA), and map MPCA bases to voxels for interpretability. Specifically, we extract low-dimensional tensors by MPCA, and then select a number of MPCA features according to the captured variance or mutual information as the input to SVM. To provide interpretability, we construct a mapping from the selected MPCA bases to raw voxels for localizing discriminating regions. Quantitative evaluations on challenging multiclass tasks demonstrate the superior performance of our proposed methods against the state-of-the-art, while qualitative analysis on localized discriminating regions shows the spatial coherence and interpretability of our mapping.","tags":[],"title":"Learning tensor-based features for whole-brain fMRI classification","type":"publication"},{"authors":["Qiquan Shi","Haiping Lu"],"categories":[],"content":"","date":1435708800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785797,"objectID":"b94ab0720930933c8a6ea967d25b81b4","permalink":"https://haipinglu.github.io/publication/shi-2015-semi/","publishdate":"2021-12-29T13:49:57.017498Z","relpermalink":"/publication/shi-2015-semi/","section":"publication","summary":"Principal component analysis (PCA) is an unsupervised method for learning low-dimensional features with orthogonal projections. Multilinear PCA methods extend PCA to deal with multidimensional data (tensors) directly via tensor-to-tensor projection or tensor-to-vector projection (TVP). However, under the TVP setting, it is difficult to develop an effective multilinear PCA method with the orthogonality constraint. This paper tackles this problem by proposing a novel Semi-Orthogonal Multilinear PCA (SO-MPCA) approach. SO-MPCA learns low-dimensional features directly from tensors via TVP by imposing the orthogonality constraint in only one mode. This formulation results in more captured variance and more learned features than full orthogonality. For better generalization, we further introduce a relaxed start (RS) strategy to get SO-MPCA-RS by fixing the starting projection vectors, which increases the bias and reduces the variance of the learning model. Experiments on both face (2D) and gait (3D) data demonstrate that SO-MPCA-RS outperforms other competing algorithms on the whole, and the relaxed start strategy is also effective for other TVP-based PCA methods.","tags":[],"title":"Semi-orthogonal multilinear PCA with relaxed start","type":"publication"},{"authors":null,"categories":null,"content":"Multilinear Subspace Learning: Dimensionality Reduction of Multidimensional Data is a book published December 16, 2013 by Chapman and Hall/CRC in the Chapman \u0026amp; Hall/CRC Press Machine Learning and Pattern Recognition Series. This page provides an overview of resources concerned with theories and applications of multilinear subspace learning (MSL). The origin of MSL traces back to multi-way analysis in the 1960s and they have been studied extensively in face and gait recognition. With more connections revealed and analogies drawn between multilinear algorithms and their linear counterparts, MSL has become an exciting area to explore for applications involving large-scale multidimensional (tensorial) data as well as a challenging problem for machine learning researchers to tackle.\n [ Book/Survey | Software | Data | Related Sites | Research Papers ]\n\nBook and Survey Multilinear Subspace Learning: Dimensionality Reduction of Multidimensional Data, Haiping Lu, K. N. Plataniotis, and A. N. Venetsanopoulos, Chapman \u0026amp; Hall/CRC Press Machine Learning and Pattern Recognition Series, Taylor and Francis, ISBN: 978-1-4398572-4-3, December 2013.\nOrder: Amazon.com, Amazon.ca, Amazon.co.uk, Amazon.fr, Amazon.de, Amazon.co.jp, ‰∫öÈ©¨ÈÄä‰∏≠ÂõΩ, CRC Press (Save 20%)\nContents: Table of Contents; Preview\nSample Chapters: Chapter 1, Chapter 3\nReview: Recommended at computingreviews.com (Review Link; PDF)\nErrata/Corrections: Errata - 19 Jan 2015, Corrections -15 Feb 2014\nSoftware: Open Source Software\nData: 2D face data \u0026amp; 3D gait data\nA Survey of Multilinear Subspace Learning for Tensor Data, Haiping Lu, K. N. Plataniotis, and A. Venetsanopoulos, Pattern Recognition, Vol. 44, No. 7, pp. 1540-1551, Jul. 2011.\nSoftware Open source software on multilinear subspace learning algorithms:\n The Matlab Tensor Toolbox MPCA: the multilinear principal component analysis algorithm, a multilinear extension of PCA, including code, data and paper. UMPCA: the uncorrelated multilinear principal component analysis algorithm, including code, data and paper. UMLDA : the uncorrelated multilinear discriminant analysis algorithm, including code, data and paper.  Data The FERET face data (2-D tensor, i.e, matrix) and training/test partitions:\nC=number of subjects; A=max angle;S: number of samples/subject\nC70A15S8 (3.09M); C80A45S6 (893K); C160A45S6 (1.32M); C240A45S6 (1.68M); C320A45S6 (2.04M).\nThe CMU PIE face data (2-D tensor, i.e, matrix) and training/test partitions: PIEP3I3 (10.2M).\nThe USF gait data version 1.7 (3-D tensor): 128x88x20 (21.2M); 64x44x20 (9.9M); 32x22x10 (3.2M).\nRelated Web Sites Wikipedia entry on Multilinear Subspace Learning.¬†Bibliography Papers relevant to MSL are ordered below according to topic, with occasional papers occurring under multiple headings.\n [ Tutorials |¬†Tensor2Tensor | Tensor2Vector ]\nTutorials Tutorial materials suitable for a first introduction to MSL. Prerequisites: elementary probability theory, statistics and linear algebra.\nH. Lu, K. N. Plataniotis, and A. N. Venetsanopoulos, Multilinear Subspace Learning: Dimensionality Reduction of Multidimensional Data, Chapman \u0026amp; Hall/CRC Press Machine Learning and Pattern Recognition Series, Taylor and Francis, ISBN: 978-1-4398572-4-3, 2013.\nH. Lu, K. N. Plataniotis, and A. N. Venetsanopoulos, A Survey of Multilinear Subspace Learning for Tensor Data, Pattern Recognition, Vol. 44, No. 7, pp. 1540-1551, Jul. 2011.\nT. G. Kolda, B. W. Bader, Tensor decompositions and applications, SIAM Review, Vol. 51, No. 3, pp. 455-500, 2009.\nL. D. Lathauwer, B. D. Moor, J. Vandewalle, On the best rank-1 and rank-(R1, R2, ..., RN ) approximation of higher-order tensors, SIAM Journal of Matrix Analysis and Applications 21 (4) (2000) 1324-1342.\nL.D. Lathauwer, B.D. Moor, J. Vandewalle, A multilinear singular value decomposition, SIAM Journal of Matrix Analysis and Applications vol. 21, no. 4, pp. 1253-1278, 2000.\nMSL through Tensor-to-Tensor Projection MSL algorithms that project a tensor directly to another tensor of lower dimension.\nH. Lu, K. N. Plataniotis, and A. N. Venetsanopoulos, MPCA: Multilinear Principal Component Analysis of Tensor Objects, IEEE Trans. on Neural Networks, Vol. 19, No. 1, Page: 18-39, Jan. 2008.\nD. Tao, X. Li, X. Wu, and S. J. Maybank, General tensor discriminant analysis and gabor features for gait recognition, IEEE Trans. Pattern Anal. Mach. Intell., vol. 29, no. 10, pp. 1700-1715, Oct. 2007.\nS. Yan, D. Xu, Q. Yang, L. Zhang, X. Tang, and H.-J. Zhang, Discriminant analysis with tensor representation, in Proc. IEEE Conference on Computer Vision and Pattern Recognition, vol. I, June 2005, pp. 526-532.\nX. He, D. Cai, P. Niyogi, Tensor subspace analysis], in: Advances in Neural Information Processing Systemsc 18 (NeurIPS), 2005.\nMSL through Tensor-to-Vector Projection MSL algorithms that project a tensor directly to a vector of lower dimension.\nH. Lu, K. N. Plataniotis, and A. N. Venetsanopoulos, Uncorrelated Multilinear Principal Component Analysis for Unsupervised Multilinear Subspace Learning, IEEE Trans. on Neural Networks, Vol. 20, No. 11, Page: 1820-1836, Nov. 2009.\nH. Lu, K. N. Plataniotis, and A. N. Venetsanopoulos, Uncorrelated Multilinear Discriminant Analysis with Regularization and Aggregation for Tensor Object Recognition, IEEE Trans. on Neural Networks, Vol. 20, No. 1, Page: 103-123, Jan. 2009.\n  This page is maintained by Haiping Lu and its layout design follows www.gaussianprocess.org. Please send suggestions for corrections or additions via email to: hplu [at] ieee [dot] org.\nLatest update: December 30, 2021.\n","date":1387152e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1387152e3,"objectID":"e51ecb7a081de1bb962ac5268d6ef32d","permalink":"https://haipinglu.github.io/project/learn-via-tensor/","publishdate":"2013-12-16T00:00:00Z","relpermalink":"/project/learn-via-tensor/","section":"project","summary":"Learn low-dimensional representations of high-dimensional data from their natural tensors","tags":["Multimodal AI","Dimension Reduction","Interpretable Machine Learning"],"title":"Learn via tensor modelling","type":"project"},{"authors":["Haiping Lu"],"categories":[],"content":"","date":1377993600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785793,"objectID":"e3855d01094b9e67e9467695d99418a2","permalink":"https://haipinglu.github.io/publication/lu-2013-learningica/","publishdate":"2021-12-29T13:49:52.889903Z","relpermalink":"/publication/lu-2013-learningica/","section":"publication","summary":"Independent component analysis (ICA) is a popular unsupervised learning method. This paper extends it to multilinear modewise ICA (MMICA) for tensors and explores two architectures in learning and recognition. MMICA models tensor data as mixtures generated from modewise source matrices that encode statistically independent information. Its sources have more compact representations than the sources in ICA. We embed ICA into the multilinear principal component analysis framework to solve for each source matrix alternatively with a few iterations. Then we obtain mixing tensors through regularized inverses of the source matrices. Simulations on synthetic data show that MMICA can estimate hidden sources accurately from structured tensor data. Moreover, in face recognition experiments, it outperforms competing solutions with both architectures.","tags":[],"title":"Learning modewise independent components from tensor data using multilinear mixing model","type":"publication"},{"authors":["Haiping Lu"],"categories":[],"content":"","date":1375315200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785792,"objectID":"e8883f4884c66be5488f681c4713d963","permalink":"https://haipinglu.github.io/publication/lu-2013-learningcca/","publishdate":"2021-12-29T13:49:51.934273Z","relpermalink":"/publication/lu-2013-learningcca/","section":"publication","summary":"Canonical correlation analysis (CCA) is a useful technique for measuring relationship between two sets of vector data. For paired tensor data sets, we propose a multilinear CCA (MCCA) method. Unlike existing multilinear variations of CCA, MCCA extracts uncorrelated features under two architectures while maximizing paired correlations. Through a pair of tensor-to-vector projections, one architecture enforces zero-correlation within each set while the other enforces zero-correlation between different pairs of the two sets. We take a successive and iterative approach to solve the problem. Experiments on matching faces of different poses show that MCCA outperforms CCA and 2D- CCA, while using much fewer features. In addition, the fusion of two architectures leads to performance improvement, indicating complementary information.","tags":[],"title":"Learning canonical correlations of paired tensor sets via tensor-to-vector projection","type":"publication"},{"authors":["Haiping Lu","Yaozhang Pan","Bappaditya Mandal","How-Lung Eng","Cuntai Guan","Derrick WS Chan"],"categories":[],"content":"","date":1359676800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785791,"objectID":"6b690d058bef2aad194b8d61f71b6c1a","permalink":"https://haipinglu.github.io/publication/lu-2012-quantifying/","publishdate":"2021-12-29T13:49:50.737109Z","relpermalink":"/publication/lu-2012-quantifying/","section":"publication","summary":"This paper proposes a color-based video analytic system for quantifying limb movements in epileptic seizure monitoring. The system utilizes colored pyjamas to facilitate limb segmentation and tracking. Thus, it is unobtrusive and requires no sensor/marker attached to patient's body. We employ Gaussian mixture models in background/foreground modeling and detect limbs through a coarse-to-fine paradigm with graph-cut-based segmentation. Next, we estimate limb parameters with domain knowledge guidance and extract displacement and oscillation features from movement trajectories for seizure detection/analysis. We report studies on sequences captured in an epilepsy monitoring unit. Experimental evaluations show that the proposed system has achieved comparable performance to EEG-based systems in detecting motor seizures.","tags":[],"title":"Quantifying limb movements in epileptic seizures through color-based video analysis","type":"publication"},{"authors":["Haiping Lu","Konstantinos N Plataniotis","Anastasios Venetsanopoulos"],"categories":[],"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785794,"objectID":"d2034ab11ff9cb4dd1250f5dfb1de5d7","permalink":"https://haipinglu.github.io/publication/lu-2013-multilinear/","publishdate":"2021-12-29T13:49:53.866603Z","relpermalink":"/publication/lu-2013-multilinear/","section":"publication","summary":"Due to advances in sensor, storage, and networking technologies, data is being generated on a daily basis at an ever-increasing pace in a wide range of applications, including cloud computing, mobile Internet, and medical imaging. This large multidimensional data requires more efficient dimensionality reduction schemes than the traditional techniques. Addressing this need, multilinear subspace learning (MSL) reduces the dimensionality of big data directly from its natural multidimensional representation, a tensor. Multilinear Subspace Learning: Dimensionality Reduction of Multidimensional Data gives a comprehensive introduction to both theoretical and practical aspects of MSL for the dimensionality reduction of multidimensional data based on tensors. It covers the fundamentals, algorithms, and applications of MSL. Emphasizing essential concepts and system-level perspectives, the authors provide a foundation for solving many of today‚Äôs most interesting and challenging problems in big multidimensional data processing. They trace the history of MSL, detail recent advances, and explore future developments and emerging applications. The book follows a unifying MSL framework formulation to systematically derive representative MSL algorithms. It describes various applications of the algorithms, along with their pseudocode. Implementation tips help practitioners in further development, evaluation, and application. The book also provides researchers with useful theoretical information on big multidimensional data in machine learning and pattern recognition. MATLAB¬Æ source code, data, and other materials are available at http://staffwww.dcs.shef.ac.uk/people/H.Lu/MSL.html","tags":[],"title":"Multilinear Subspace Learning: Dimensionality Reduction Of Multidimensional Data","type":"publication"},{"authors":["Bappaditya Mandal","How-Lung Eng","Haiping Lu","Derrick WS Chan","Yen-Ling Ng"],"categories":[],"content":"","date":1343779200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785790,"objectID":"a7b7ba97f1fdf0f422dcef6f6f62c85b","permalink":"https://haipinglu.github.io/publication/mandal-2012-non/","publishdate":"2021-12-29T13:49:49.578145Z","relpermalink":"/publication/mandal-2012-non/","section":"publication","summary":"In this work we propose a non-intrusive video analytic system for patient's body parts movement analysis in Epilepsy Monitoring Unit. The system utilizes skin color modeling, head/face pose template matching and face detection to analyze and quantify the head movements. Epileptic patients' heads are analyzed holistically to infer seizure and normal random movements. The patient does not require to wear any special clothing, markers or sensors, hence it is totally non-intrusive. The user initializes the person-specific skin color and selects few face/head poses in the initial few frames. The system then tracks the head/face and extracts spatio-temporal features. Support vector machines are then used on these features to classify seizure-like movements from normal random movements. Experiments are performed on numerous long hour video sequences captured in an Epilepsy Monitoring Unit at a local hospital. The results demonstrate the feasibility of the proposed system in pediatric epilepsy monitoring and seizure detection.","tags":[],"title":"Non-intrusive head movement analysis of videotaped seizures of epileptic origin","type":"publication"},{"authors":["Haiping Lu","How-Lung Eng","Bappaditya Mandal","Derrick WS Chan","Yen-Ling Ng"],"categories":[],"content":"","date":1312156800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785796,"objectID":"a366e73d66ef68157fc31a32581f37ae","permalink":"https://haipinglu.github.io/publication/lu-2011-markerless/","publishdate":"2021-12-29T13:49:55.963705Z","relpermalink":"/publication/lu-2011-markerless/","section":"publication","summary":"This paper proposes a markerless video analytic system for quantifying body part movements in pediatric epilepsy monitoring. The system utilizes colored pajamas worn by a patient in bed to extract body part movement trajectories, from which various features can be obtained for seizure detection and analysis. Hence, it is non-intrusive and it requires no sensor/marker to be attached to the patient's body. It takes raw video sequences as input and a simple user-initialization indicates the body parts to be examined. In background/foreground modeling, Gaussian mixture models are employed in conjunction with HSV-based modeling. Body part detection follows a coarse-to-fine paradigm with graph-cut-based segmentation. Finally, body part parameters are estimated with domain knowledge guidance. Experimental studies are reported on sequences captured in an Epilepsy Monitoring Unit at a local hospital. The results demonstrate the feasibility of the proposed system in pediatric epilepsy monitoring and seizure detection.","tags":[],"title":"Markerless video analysis for movement quantification in pediatric epilepsy monitoring","type":"publication"},{"authors":["Haiping Lu","Konstantinos N Plataniotis","Anastasios N Venetsanopoulos"],"categories":[],"content":"","date":1309478400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785788,"objectID":"f79336528f53316410f48bf2af672600","permalink":"https://haipinglu.github.io/publication/lu-2011-survey/","publishdate":"2021-12-29T13:49:47.59698Z","relpermalink":"/publication/lu-2011-survey/","section":"publication","summary":"Increasingly large amount of multidimensional data are being generated on a daily basis in many applications. This leads to a strong demand for learning algorithms to extract useful information from these massive data. This paper surveys the field of multilinear subspace learning (MSL) for dimensionality reduction of multidimensional data directly from their tensorial representations. It discusses the central issues of MSL, including establishing the foundations of the field via multilinear projections, formulating a unifying MSL framework for systematic treatment of the problem, examining the algorithmic aspects of typical MSL solutions, and categorizing both unsupervised and supervised MSL algorithms into taxonomies. Lastly, the paper summarizes a wide range of MSL applications and concludes with perspectives on future research directions.","tags":[],"title":"A survey of multilinear subspace learning for tensor data","type":"publication"},{"authors":["Haiping Lu","How-Lung Eng","Cuntai Guan","Konstantinos N Plataniotis","Anastasios N Venetsanopoulos"],"categories":[],"content":"","date":1291161600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785777,"objectID":"fa6b03fc2ecff233bdabe286bbfbfeee","permalink":"https://haipinglu.github.io/publication/lu-2010-regularized/","publishdate":"2021-12-29T13:49:36.818083Z","relpermalink":"/publication/lu-2010-regularized/","section":"publication","summary":"Common spatial pattern (CSP) is a popular algorithm for classifying electroencephalogram (EEG) signals in the context of brain-computer interfaces (BCIs). This paper presents a regularization and aggregation technique for CSP in a small-sample setting (SSS). Conventional CSP is based on a sample-based covariance-matrix estimation. Hence, its performance in EEG classification deteriorates if the number of training samples is small. To address this concern, a regularized CSP (R-CSP) algorithm is proposed, where the covariance-matrix estimation is regularized by two parameters to lower the estimation variance while reducing the estimation bias. To tackle the problem of regularization parameter determination, R-CSP with aggregation (R-CSP-A) is further proposed, where a number of R-CSPs are aggregated to give an ensemble-based solution. The proposed algorithm is evaluated on data set IVa of BCI Competition III against four other competing algorithms. Experiments show that R-CSP-A significantly outperforms the other methods in average classification performance in three sets of experiments across various testing scenarios, with particular superiority in SSS.","tags":[],"title":"Regularized common spatial pattern with aggregation for EEG classification in small-sample setting","type":"publication"},{"authors":["Haiping Lu","How-Lung Eng","Myo Thida","Konstantinos N Plataniotis"],"categories":[],"content":"","date":1285891200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785787,"objectID":"02374616c9c711bff463cb775065946e","permalink":"https://haipinglu.github.io/publication/lu-2010-visualization/","publishdate":"2021-12-29T13:49:46.738786Z","relpermalink":"/publication/lu-2010-visualization/","section":"publication","summary":"This paper presents a novel approach for the visualization and clustering of crowd video contents by using multilinear principal component analysis (MPCA). In contrast to feature-point-based approach and frame-based dimensionality reduction approach, the proposed method maps each short video segment to a point in MPCA subspace to take temporal information into account naturally through tensorial representations. Specifically, MPCA projects each short segment of a video to a low-dimensional tensor first. A few MPCA features are then selected according to the variance captured as the final representation. Thus, a video is visualized as a trajectory in MPCA subspace. The trajectory generated enables visual interpretation of video content in a compact space as well as visual clustering of video events. The proposed method is evaluated on the PETS 2009 datasets through comparison with three existing methods for video visualization. The MPCA visualization shows superior performance in clustering segments of the same event as well as identifying the transitions between events.","tags":[],"title":"Visualization and clustering of crowd video content in MPCA subspace","type":"publication"},{"authors":["Francis Minhthang Bui","Karl Martin","Haiping Lu","Konstantinos N Plataniotis","Dimitrios Hatzinakos"],"categories":[],"content":"","date":1267401600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785771,"objectID":"2a194895f5d26ac45a9a458008611fad","permalink":"https://haipinglu.github.io/publication/bui-2009-fuzzy/","publishdate":"2021-12-29T13:49:30.276958Z","relpermalink":"/publication/bui-2009-fuzzy/","section":"publication","summary":"Biometric encryption (BE) has recently been identified as a promising paradigm to deliver security and privacy, with unique technical merits and encouraging social implications. An integral component in BE is a key binding method, which is the process of securely combining a signal, containing sensitive information to be protected (i.e., the key), with another signal derived from physiological features (i.e., the biometric). A challenge to this approach is the high degree of noise and variability present in physiological signals. As such, fuzzy methods are needed to enable proper operations, with adequate performance results in terms of false acceptance rate and false rejection rate. In this work, the focus will be on a class of fuzzy key binding methods based on dirty paper coding known as quantization index modulation. While the methods presented are applicable to a wide range of biometric modalities, the face biometric is selected for illustrative purposes, in evaluating the QIM-based solutions for BE systems. Performance evaluation of the investigated methods is reported using data from the CMU PIE face database.","tags":[],"title":"Fuzzy key binding strategies based on quantization index modulation (QIM) for biometric encryption (BE) applications","type":"publication"},{"authors":["Karl Martin","Haiping Lu","Francis M. Bui","Konstantinos N Plataniotis","Dimitrios Hatzinakos"],"categories":[],"content":"","date":1259625600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785782,"objectID":"49e6aa254494e58879c030dad746f1ba","permalink":"https://haipinglu.github.io/publication/martin-2009-biometric/","publishdate":"2021-12-29T13:49:41.970794Z","relpermalink":"/publication/martin-2009-biometric/","section":"publication","summary":"This paper presents a biometric encryption system that addresses the privacy concern in the deployment of the face recognition technology in real-world systems. In particular, we focus on a self-exclusion scenario (a special application of watch-list) of face recognition and propose a novel design of a biometric encryption system deployed with a face recognition system under constrained conditions. From a system perspective, we investigate issues ranging from image preprocessing, feature extraction, to cryptography, error-correcting coding/decoding, key binding, and bit allocation. In simulation studies, the proposed biometric encryption system is tested on the CMU PIE face database. An important observation from the simulation results is that in the proposed system, the biometric encryption module tends to significantly reduce the false acceptance rate with a marginal increase in the false rejection rate.","tags":[],"title":"A biometric encryption system for the self-exclusion scenario of face recognition","type":"publication"},{"authors":["Haiping Lu","Konstantinos N Plataniotis","Anastasios N Venetsanopoulos"],"categories":[],"content":"","date":1257033600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785779,"objectID":"f381bd36c8299dae03d69afa4173e365","permalink":"https://haipinglu.github.io/publication/lu-2009-uncorrelatedpca/","publishdate":"2021-12-29T13:49:38.648366Z","relpermalink":"/publication/lu-2009-uncorrelatedpca/","section":"publication","summary":"This paper proposes an uncorrelated multilinear principal component analysis (UMPCA) algorithm for unsupervised subspace learning of tensorial data. It should be viewed as a multilinear extension of the classical principal component analysis (PCA) framework. Through successive variance maximization, UMPCA seeks a tensor-to-vector projection (TVP) that captures most of the variation in the original tensorial input while producing uncorrelated features. The solution consists of sequential iterative steps based on the alternating projection method. In addition to deriving the UMPCA framework, this work offers a way to systematically determine the maximum number of uncorrelated multilinear features that can be extracted by the method. UMPCA is compared against the baseline PCA solution and its five state-of-the-art multilinear extensions, namely two-dimensional PCA (2DPCA), concurrent subspaces analysis (CSA), tensor rank-one decomposition (TROD), generalized PCA (GPCA), and multilinear PCA (MPCA), on the tasks of unsupervised face and gait recognition. Experimental results included in this paper suggest that UMPCA is particularly effective in determining the low-dimensional projection space needed in such recognition tasks.","tags":[],"title":"Uncorrelated multilinear principal component analysis for unsupervised multilinear subspace learning","type":"publication"},{"authors":["Haiping Lu","Konstantinos N Plataniotis","Anastasios N Venetsanopoulos"],"categories":[],"content":"","date":1254355200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785785,"objectID":"ced63d9cae24c4359b9980c7771f31f4","permalink":"https://haipinglu.github.io/publication/lu-2009-boosting/","publishdate":"2021-12-29T13:49:44.692225Z","relpermalink":"/publication/lu-2009-boosting/","section":"publication","summary":"This paper proposes a boosted linear discriminant analysis (LDA) solution on features extracted by the multilinear principal component analysis (MPCA) to enhance gait recognition performance. Three-dimensional gait objects are projected in the MPCA space first to obtain low-dimensional tensorial features. Then, lower-dimensional vectorial features are obtained through discriminative feature selection. These feature vectors are then fed into an LDA-style booster, where several regularized and weakened LDA learners work together to produce a strong learner through a novel feature weighting and sampling process. The LDA learner employs a simple nearest-neighbor classifier with a weighted angle distance measure for classification. The experimental results on the NIST/USF \"Gait Challenge\" data-sets show that the proposed solution has successfully improved the gait recognition performance and outperformed several state-of-the-art gait recognition algorithms.","tags":[],"title":"Boosting discriminant learners for gait recognition using MPCA features","type":"publication"},{"authors":["Haiping Lu","Konstantinos N Plataniotis","Anastasios N Venetsanopoulos"],"categories":[],"content":"","date":1251763200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785774,"objectID":"bbc3391381544aaa4525531d68d44af5","permalink":"https://haipinglu.github.io/publication/lu-2009-regularized/","publishdate":"2021-12-29T13:49:33.397878Z","relpermalink":"/publication/lu-2009-regularized/","section":"publication","summary":"The common spatial patterns (CSP) algorithm is commonly used to extract discriminative spatial filters for the classification of electroencephalogram (EEG) signals in the context of brain-computer interfaces (BCIs). However, CSP is based on a sample-based covariance matrix estimation. Therefore, its performance is limited when the number of available training samples is small. In this paper, the CSP method is considered in such a small-sample setting. We propose a regularized common spatial patterns (R-CSP) algorithm by incorporating the principle of generic learning. The covariance matrix estimation in R-CSP is regularized through two regularization parameters to increase the estimation stability while reducing the estimation bias due to limited number of training samples. The proposed method is tested on data set IVa of the third BCI competition and the results show that R-CSP can outperform the classical CSP algorithm by 8.5% on average. Moreover, the regularization introduced is particularly effective in the small-sample setting.","tags":[],"title":"Regularized common spatial patterns with generic learning for EEG signal classification","type":"publication"},{"authors":["Haiping Lu","Karl Martin","Francis Bui","Konstantinos N Plataniotis","Dimitris Hatzinakos"],"categories":[],"content":"","date":1246406400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785786,"objectID":"d5742ae213f1c0ccb61887a4e37c7c68","permalink":"https://haipinglu.github.io/publication/lu-2009-face/","publishdate":"2021-12-29T13:49:45.677277Z","relpermalink":"/publication/lu-2009-face/","section":"publication","summary":"Face recognition has been employed in various security-related applications such as surveillance, mugshot identification, e-passport, and access control. Despite its recent advancements, privacy concern is one of several issues preventing its wider deployment. In this paper, we address the privacy concern for a self-exclusion scenario of face recognition, through combining face recognition with a simple biometric encryption scheme called helper data system. The combined system is described in detail with focus on the key binding procedure. Experiments are carried out on the CMU PIE face database. The experimental results demonstrate that in the proposed system, the biometric encryption module tends to significantly reduce the false acceptance rate while increasing the false rejection rate.","tags":[],"title":"Face recognition with biometric encryption for privacy-enhancing self-exclusion","type":"publication"},{"authors":["Jie Wang","Haiping Lu","Konstantinos N Plataniotis","Juwei Lu"],"categories":[],"content":"","date":1246406400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785776,"objectID":"e6029b89e6867d3c78a03e88c39cbc6a","permalink":"https://haipinglu.github.io/publication/wang-2009-gaussian/","publishdate":"2021-12-29T13:49:35.637257Z","relpermalink":"/publication/wang-2009-gaussian/","section":"publication","summary":"This paper presents a novel algorithm to optimize the Gaussian kernel for pattern classification tasks, where it is desirable to have well-separated samples in the kernel feature space. We propose to optimize the Gaussian kernel parameters by maximizing a classical class separability criterion, and the problem is solved through a quasi-Newton algorithm by making use of a recently proposed decomposition of the objective criterion. The proposed method is evaluated on five data sets with two kernel-based learning algorithms. The experimental results indicate that it achieves the best overall classification performance, compared with three competing solutions. In particular, the proposed method provides a valuable kernel optimization solution in the severe small sample size scenario.","tags":[],"title":"Gaussian kernel optimization for pattern classification","type":"publication"},{"authors":["Haiping Lu","Jie Wang","Konstantinos N Plataniotis"],"categories":[],"content":"","date":1230768e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785781,"objectID":"419d0c315269330493434d1f89654b4e","permalink":"https://haipinglu.github.io/publication/lu-2009-review/","publishdate":"2021-12-29T13:49:40.976184Z","relpermalink":"/publication/lu-2009-review/","section":"publication","summary":"Face and gait recognition belong to the field of biometrics, a very active area of research in the computer vision and pattern recognition society, and face and gait are two typical physiological and behavioral biometrics, respectively. This chapter provides a survey on face and gait recognition and presents an overview of the face and gait recognition systems, where the key components are described and the two common approaches are introduced. The approaches are the model-based approach and the appearance-based approach. It reviews the fusion of face and gait for recognition and details several commonly used face and gait databases. The chapter presents various feature extraction algorithms for face and gait recognition, ranging from linear, nonlinear to multilinear subspace learning algorithms. The development of face or gait recognition algorithms largely depends on the availability of large and representative public databases of face images or gait sequences so that algorithms can be compared and advancements can be measured.","tags":[],"title":"A review on face and gait recognition: system, data and algorithms","type":"publication"},{"authors":["Haiping Lu","Konstantinos N Plataniotis","Anastasios N Venetsanopoulos"],"categories":[],"content":"","date":1230768e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785778,"objectID":"9f701ea93ddac971e70bb98e4adb0eeb","permalink":"https://haipinglu.github.io/publication/lu-2009-taxonomy/","publishdate":"2021-12-29T13:49:37.783338Z","relpermalink":"/publication/lu-2009-taxonomy/","section":"publication","summary":"Biometric signals are mostly multidimensional objects, known as tensors. Recently, there has been a growing interest in multilinear discriminant analysis (MLDA) solutions operating directly on these tensorial data. However, the relationships among these algorithms and their connections to linear (vector-based) algorithms are not clear, and in-depth understanding is needed for further developments and applications. In this chapter, we introduce the basics needed in understanding existing MLDA solutions and then categorize them according to the multilinear projection employed, while pointing out their connections with traditional linear solutions at the same time. A number of commonly used objective criteria and initialization methods are discussed. Experiments are carried out on two public face databases to evaluate the performance of the MLDA variants, and the results show that MLDA (and multilinear learning algorithms in general) is a promising field with great research potential.","tags":[],"title":"A taxonomy of emerging multilinear discriminant analysis solutions for biometric signal recognition","type":"publication"},{"authors":["Haiping Lu","Konstantinos N Plataniotis","Anastasios N Venetsanopoulos"],"categories":[],"content":"","date":1230768e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785767,"objectID":"d75b0934d7e20eb9de139efa7aa8b3b2","permalink":"https://haipinglu.github.io/publication/lu-2009-uncorrelatedlda/","publishdate":"2021-12-29T13:49:25.921829Z","relpermalink":"/publication/lu-2009-uncorrelatedlda/","section":"publication","summary":"This paper proposes an uncorrelated multilinear discriminant analysis (UMLDA) framework for the recognition of multidimensional objects, known as tensor objects. Uncorrelated features are desirable in recognition tasks since they contain minimum redundancy and ensure independence of features. The UMLDA aims to extract uncorrelated discriminative features directly from tensorial data through solving a tensor-to-vector projection. The solution consists of sequential iterative processes based on the alternating projection method, and an adaptive regularization procedure is incorporated to enhance the performance in the small sample size (SSS) scenario. A simple nearest-neighbor classifier is employed for classification. Furthermore, exploiting the complementary information from differently initialized and regularized UMLDA recognizers, an aggregation scheme is adopted to combine them at the matching score level, resulting in enhanced generalization performance while alleviating the regularization parameter selection problem. The UMLDA-based recognition algorithm is then empirically shown on face and gait recognition tasks to outperform four multilinear subspace solutions (MPCA, DATER, GTDA, TR1DA) and four linear subspace solutions (Bayesian, LDA, ULDA, R-JD-LDA).","tags":[],"title":"Uncorrelated multilinear discriminant analysis with regularization and aggregation for tensor object recognition","type":"publication"},{"authors":["Haiping Lu"],"categories":[],"content":"","date":1217548800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785780,"objectID":"61bd81f3036887be07b3c549115129ac","permalink":"https://haipinglu.github.io/publication/haiping-ph-dthesis/","publishdate":"2021-12-29T13:49:39.947771Z","relpermalink":"/publication/haiping-ph-dthesis/","section":"publication","summary":"Face and gait recognition problems are challenging due to largely varying appearances, highly complex pattern distributions, and insufficient training samples. This dissertation focuses on multilinear subspace learning for face and gait recognition, where low-dimensional representations are learned directly from tensorial face or gait objects. This research introduces a unifying multilinear subspace learning framework for systematic treatment of the multilinear subspace learning problem. Three multilinear projections are categorized according to the input-output space mapping as: vector-to-vector projection, tensor-to-tensor projection, and tensor-to-vector projection. Techniques for subspace learning from tensorial data are then proposed and analyzed. Multilinear principal component analysis (MPCA) seeks a tensor-to-tensor projection that maximizes the variation captured in the projected space, and it is further combined with linear discriminant analysis and boosting for better recognition performance. Uncorrelated MPCA (UMPCA) solves for a tensor-to-vector projection that maximizes the captured variation in the projected space while enforcing the zero-correlation constraint. Uncorrelated multilinear discriminant analysis (UMLDA) aims to produce uncorrelated features through a tensor-to-vector projection that maximizes a ratio of the between-class scatter over the within-class scatter defined in the projected space. Regularization and aggregation are incorporated in the UMLDA solution for enhanced performance. Experimental studies and comparative evaluations are presented and analyzed on the PIE and FERET face databases, and the USF gait database. The results indicate that the MPCA-based solution has achieved the best overall performance in various learning scenarios, the UMLDA-based solution has produced the most stable and competitive results with the same parameter setting, and the UMPCA algorithm is effective in unsupervised learning in low-dimensional subspace. Besides advancing the state-of-the-art of multilinear subspace learning for face and gait recognition, this dissertation also has potential impact in both the development of new multilinear subspace learning algorithms and other applications involving tensor objects.","tags":[],"title":"Multilinear Subspace Learning for Face and Gait Recognition","type":"publication"},{"authors":["Haiping Lu","Konstantinos N Plataniotis","Anastasios N Venetsanopoulos"],"categories":[],"content":"","date":1214870400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785775,"objectID":"48c6e19fca0beb422dee3250bbd6ea52","permalink":"https://haipinglu.github.io/publication/lu-2008-uncorrelatedpca/","publishdate":"2021-12-29T13:49:34.221394Z","relpermalink":"/publication/lu-2008-uncorrelatedpca/","section":"publication","summary":"Tensorial data are frequently encountered in various machine learning tasks today and dimensionality reduction is one of their most important applications. This paper extends the classical principal component analysis (PCA) to its multilinear version by proposing a novel unsupervised dimensionality reduction algorithm for tensorial data, named as uncorrelated multilinear PCA (UMPCA). UMPCA seeks a tensor-to-vector projection that captures most of the variation in the original tensorial input while producing uncorrelated features through successive variance maximization. We evaluate the UMPCA on a second-order tensorial problem, face recognition, and the experimental results show its superiority, especially in low-dimensional spaces, through the comparison with three other PCA-based algorithms.","tags":[],"title":"Uncorrelated multilinear principal component analysis through successive variance maximization","type":"publication"},{"authors":["Haiping Lu","Konstantinos N Plataniotis","Anastasios N Venetsanopoulos"],"categories":[],"content":"","date":1199145600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785770,"objectID":"2eba1cb5be92ba1d7446ae0742346d2d","permalink":"https://haipinglu.github.io/publication/lu-2008-full/","publishdate":"2021-12-29T13:49:29.315162Z","relpermalink":"/publication/lu-2008-full/","section":"publication","summary":"This paper proposes a full-body layered deformable model (LDM) inspired by manually labeled silhouettes for automatic model-based gait recognition from part-level gait dynamics in monocular video sequences. The LDM is defined for the fronto-parallel gait with 22 parameters describing the human body part shapes (widths and lengths) and dynamics (positions and orientations). There are four layers in the LDM and the limbs are deformable. Algorithms for LDM-based human body pose recovery are then developed to estimate the LDM parameters from both manually labeled and automatically extracted silhouettes, where the automatic silhouette extraction is through a coarse-to-fine localization and extraction procedure. The estimated LDM parameters are used for model-based gait recognition by employing the dynamic time warping for matching and adopting the combination scheme in AdaBoost.M2. While the existing model-based gait recognition approaches focus primarily on the lower limbs, the estimated LDM parameters enable us to study full-body model-based gait recognition by utilizing the dynamics of the upper limbs, the shoulders and the head as well. In the experiments, the LDM-based gait recognition is tested on gait sequences with differences in shoe-type, surface, carrying condition and time. The results demonstrate that the recognition performance benefits from not only the lower limb dynamics, but also the dynamics of the upper limbs, the shoulders and the head. In addition, the LDM can serve as an analysis tool for studying factors affecting the gait under various conditions.","tags":[],"title":"A full-body layered deformable model for automatic model-based gait recognition","type":"publication"},{"authors":["Alex Chi Chung Kot","Huijuan Yang","Haiping Lu"],"categories":[],"content":"","date":1199145600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785784,"objectID":"2b1317c6a46a53ce1bd9cd68dd786211","permalink":"https://haipinglu.github.io/publication/kot-2008-method/","publishdate":"2021-12-29T13:49:43.864753Z","relpermalink":"/publication/kot-2008-method/","section":"publication","summary":"A method of embedding watermark data into a two-colour (binary) image includes dividing the image into blocks and assessing the suitability of each block to embed a bit of watermark data by assessing whether or not the flipping of a defined pixel in each block affects the visual attributes of said block in manner to be perceptible by the human eye. Data is only embedded in those blocks determined to be suitable for data embedding, by flipping the defined pixel, as required. A recipient of the document may similarly assess which blocks contain watermark data, by assessing the suitability of each block in the document to embed such data. Conveniently, watermark data may be extracted without further information about the data's location within a document.","tags":[],"title":"Method, software, and device for hiding data in binary image, while preserving image quality","type":"publication"},{"authors":["Haiping Lu","Konstantinos N Plataniotis","Anastasios N Venetsanopoulos"],"categories":[],"content":"","date":1199145600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785761,"objectID":"ec405ff317b5b8021d71fd40164a6183","permalink":"https://haipinglu.github.io/publication/lu-2008-mpca/","publishdate":"2021-12-29T13:49:20.893457Z","relpermalink":"/publication/lu-2008-mpca/","section":"publication","summary":"This paper introduces a multilinear principal component analysis (MPCA) framework for tensor object feature extraction. Objects of interest in many computer vision and pattern recognition applications, such as 2D/3D images and video sequences are naturally described as tensors or multilinear arrays. The proposed framework performs feature extraction by determining a multilinear projection that captures most of the original tensorial input variation. The solution is iterative in nature and it proceeds by decomposing the original problem to a series of multiple projection subproblems. As part of this work, methods for subspace dimensionality determination are proposed and analyzed. It is shown that the MPCA framework discussed in this work supplants existing heterogeneous solutions such as the classical principal component analysis (PCA) and its 2D variant (2D PCA). Finally, a tensor object recognition system is proposed with the introduction of a discriminative tensor feature selection mechanism and a novel classification strategy, and applied to the problem of gait recognition. Results presented here indicate MPCA's utility as a feature extraction tool. It is shown that even without a fully optimized design, an MPCA-based gait recognition module achieves highly competitive performance and compares favorably to the state-of-the-art gait recognizers.","tags":[],"title":"MPCA: Multilinear principal component analysis of tensor objects","type":"publication"},{"authors":["Haiping Lu","Konstantinos N Plataniotis","Anastasios Venetsanopoulos"],"categories":[],"content":"","date":1188604800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785799,"objectID":"a19a6694007dade746fe3663cbc6a007","permalink":"https://haipinglu.github.io/publication/lu-2007-boosting/","publishdate":"2021-12-29T13:49:59.0303Z","relpermalink":"/publication/lu-2007-boosting/","section":"publication","summary":"In this paper, we present a boosted linear discriminant analysis (LDA) solution with regularization on features extracted by the multilinear principal component analysis (MPCA) for the gait recognition problem. This work is an extension of a recent LDA-based boosting approach and the MPCA is employed to project tensorial gait samples on a number of discriminative EigenTensorGaits (ETGs) to produce gait feature vectors for the base learners in boosting. This new scheme offers one more way to control the learner weakness while being very computationally efficient. Furthermore, the LDA learners are modified through regularization for protection against overfitting on the gallery set. Promising experimental results obtained on the Gait Challenge data sets indicate that the proposed algorithm is an efficient and effective solution consistently enhancing the gait recognition results on the seven probe sets by MPCA+LDA.","tags":[],"title":"Boosting LDA with regularization on MPCA features for gait recognition","type":"publication"},{"authors":["Haiping Lu","KN Plataniotis","AN Venetsanopoulos"],"categories":[],"content":"","date":1188604800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785815,"objectID":"50028301134c52b2419724f1fdf3aa3c","permalink":"https://haipinglu.github.io/publication/lu-2007-uncorrelated/","publishdate":"2021-12-29T13:50:14.29407Z","relpermalink":"/publication/lu-2007-uncorrelated/","section":"publication","summary":"This paper proposes a novel uncorrelated multilinear discriminant analysis (UMLDA) algorithm for the challenging problem of gait recognition. A tensor-to-vector projection (TVP) of tensor objects is formulated and the UMLDA is developed using TVP to extract uncorrelated discriminative features directly from tensorial data. The small-sample-size (SSS) problem present when discriminant solutions are applied to the problem of gait recognition is discussed and a regularization procedure is introduced to address it. The effectiveness of the proposed regularization is demonstrated in the experiments and the regularized UMLDA algorithm is shown to outperform other multilinear subspace solutions in gait recognition.","tags":[],"title":"Uncorrelated multilinear discriminant analysis with regularization for gait recognition","type":"publication"},{"authors":["Haiping Lu","Konstantinos N Plataniotis","Anastasios Venetsanopoulos"],"categories":[],"content":"","date":1157068800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785795,"objectID":"6b7085a9a7dd1602dbb7e83c1604eb10","permalink":"https://haipinglu.github.io/publication/lu-2006-gait/","publishdate":"2021-12-29T13:49:54.869352Z","relpermalink":"/publication/lu-2006-gait/","section":"publication","summary":"This paper solves the gait recognition problem in a multilinear principal component analysis (MPCA) framework. Gait sequences are naturally described as tensor objects and feature extraction for tensor objects is important in computer vision and pattern recognition applications. Classical principal component analysis (PCA) operates on vectors and it is not directly applicable to gait sequences. This work introduces an MPCA framework for feature extraction from gait sequences by seeking a multilinear projection onto a tensor subspace of lower dimensionality which captures most of the variance of the original gait samples. A subset of the extracted eigen-tensors are selected and the classical LDA is then applied. In experiments, gait recognition results are reported on the Gait Challenge data sets using the proposed solution. The results indicate that with a simple design, the proposed algorithm outperforms the state-of-the-art algorithms.","tags":[],"title":"Gait recognition through MPCA plus LDA","type":"publication"},{"authors":["Haiping Lu","Konstantinos N Plataniotis","Anastasios N Venetsanopoulos"],"categories":[],"content":"","date":1154390400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785765,"objectID":"28757e9cbfe4f7c023ddd496fef59770","permalink":"https://haipinglu.github.io/publication/lu-2006-multilinear/","publishdate":"2021-12-29T13:49:25.154767Z","relpermalink":"/publication/lu-2006-multilinear/","section":"publication","summary":"In this paper, a multilinear formulation of the popular principal component analysis (PCA) is proposed, named as multilinear PCA (MPCA), where the input can be not only vectors, but also matrices or higher-order tensors. It is a natural extension of PCA and the analogous counterparts in MPCA to the eigenvalues and eigenvectors in PCA are defined. The proposed MPCA has wide range of applications as a higher-order generalization of PCA. As an example, MPCA is applied to the problem of gait recognition using a novel representation called EigenTensorGait. A gait sequence is divided into half gait cycles and each half cycle, represented as a 3rd-order tensor, is considered as one data sample. Experiments show that the proposed MPCA performs better than the baseline algorithm in human identification on the gait challenge data sets.","tags":[],"title":"Multilinear principal component analysis of tensor objects for recognition","type":"publication"},{"authors":["Haiping Lu","Konstantinos N Plataniotis","Anastasios N Venetsanopoulos"],"categories":[],"content":"","date":1151712e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785772,"objectID":"4043c5c93ee9b3195eb61c88e42ecfae","permalink":"https://haipinglu.github.io/publication/lu-2006-coarse/","publishdate":"2021-12-29T13:49:31.255057Z","relpermalink":"/publication/lu-2006-coarse/","section":"publication","summary":"This paper presents a localized coarse-to-fine algorithm for efficient and accurate pedestrian localization and silhouette extraction for the gait challenge data sets. The coarse detection phase is simple and fast. It locates the target quickly based on temporal differences and some knowledge on the human target. Based on this coarse detection, the fine detection phase applies a robust background subtraction algorithm to the coarse target regions and the detection obtained is further processed to produce the final results. This algorithm has been tested on 285 outdoor sequences from the gait challenge data sets, with wide variety of capture conditions. The pedestrian targets are localized very well and silhouettes extracted resemble the manually labeled silhouettes closely.","tags":[],"title":"Coarse-to-fine pedestrian localization and silhouette extraction for the gait challenge data sets","type":"publication"},{"authors":["Haiping Lu","Konstantinos N Plataniotis","Anastasios N Venetsanopoulos"],"categories":[],"content":"","date":1143849600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785769,"objectID":"7e30602fa2debdab26b7240264ecc628","permalink":"https://haipinglu.github.io/publication/lu-2006-layered/","publishdate":"2021-12-29T13:49:28.130697Z","relpermalink":"/publication/lu-2006-layered/","section":"publication","summary":"In this paper, a layered deformable model (LDM) is proposed for human body pose recovery in gait analysis. This model is inspired by the manually labeled silhouettes in (Z. Liu, et al., July 2004) and it is designed to closely match them. For fronto-parallel gait, the introduced LDM model defines the body part widths and lengths, the position and the joint angles of human body using 22 parameters. The model consists of four layers and allows for limb deformation. With this model, our objective is to recover its parameters (and thus the human body pose) from automatically extracted silhouettes. LDM recovery algorithm is first developed for manual silhouettes, in order to generate ground truth sequences for comparison and useful statistics regarding the LDM parameters. It is then extended for automatically extracted silhouettes. The proposed methodologies have been tested on 10005 frames from 285 gait sequences captured under various conditions and an average error rate of 7% is achieved for the lower limb joint angles of all the frames, showing great potential for model-based gait recognition","tags":[],"title":"A layered deformable model for gait analysis","type":"publication"},{"authors":["Haiping Lu","Yun Q Shi","Alex C Kot","Lihui Chen"],"categories":[],"content":"","date":1104537600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785789,"objectID":"9ea0e4a37ba897cd88a0723ace4db079","permalink":"https://haipinglu.github.io/publication/lu-2005-binary/","publishdate":"2021-12-29T13:49:48.62577Z","relpermalink":"/publication/lu-2005-binary/","section":"publication","summary":"Digital watermarking has been proposed for the protection of digital medias. This paper presents two watermarking algorithms for binary images. Both algorithms involve a blurring preprocessing and a biased binarization. After the blurring, the first algorithm embeds a watermark by modifying the DC components of the Discrete Cosine Transform (DCT), followed by a biased binarization, and the second one embeds a watermark by directly biasing the binarization threshold of the blurred image, controlled by a loop. Experimental results show the imperceptibility and robustness aspects of both algorithms.","tags":[],"title":"Binary image watermarking through blurring and biased binarization","type":"publication"},{"authors":["Haiping Lu","Alex C Kot","Yun Q Shi"],"categories":[],"content":"","date":1075593600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785765,"objectID":"390affe57a6bfc1728b46590e827304a","permalink":"https://haipinglu.github.io/publication/lu-2004-distance/","publishdate":"2021-12-29T13:49:24.017939Z","relpermalink":"/publication/lu-2004-distance/","section":"publication","summary":"In this letter, we present a novel objective distortion measure for binary document images. This measure is based on the reciprocal of distance that is straightforward to calculate. Our results show that the proposed distortion measure matches well to subjective evaluation by human visual perception.","tags":[],"title":"Distance-reciprocal distortion measure for binary document images","type":"publication"},{"authors":["Haiping Lu","Alex C Kot","Rahardja Susanto"],"categories":[],"content":"","date":1057017600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785783,"objectID":"13069f497013cf1b4f8b3ab5d6ecc4fa","permalink":"https://haipinglu.github.io/publication/lu-2003-binary/","publishdate":"2021-12-29T13:49:42.870957Z","relpermalink":"/publication/lu-2003-binary/","section":"publication","summary":"This paper presents a watermarking algorithm for binary images. The original binary image is blurred to a gray-level image and we embed the watermark by biasing the threshold in binarization. A loop is used to control the quality of watermarked images and robustness, and a key is generated for extraction. We employ error correction codes to reduce extraction error. This algorithm can be applied to general binary images except dithered images. Experiments show that the distortion in the watermarked image is not obtrusive and the algorithm provides some degree of robustness.","tags":[],"title":"Binary image watermarking through biased binarization","type":"publication"},{"authors":["Haiping Lu","Alex C Kot","Jun Cheng"],"categories":[],"content":"","date":1051747200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785762,"objectID":"680a6b782bc53ae6d10bd68f37e262b1","permalink":"https://haipinglu.github.io/publication/lu-2003-secure/","publishdate":"2021-12-29T13:49:22.018998Z","relpermalink":"/publication/lu-2003-secure/","section":"publication","summary":"In this paper, we present a data hiding algorithm for binary document images. This algorithm is based on the Distance-Reciprocal Distortion Measure that is used to evaluate the amount of distortion caused by flipping a particular pixel in binary document images. The pixels that will cause less distortion after flipping are preferred candidates for flipping. We do the embedding by enforcing the odd-even features of non-uniform blocks and employ a 2-D shifting to provide security for tamper proofing and authentication. Experiments show that the watermark-embedded document image has good quality and tampering of content can be detected successfully.","tags":[],"title":"Secure data hiding in binary document images for authentication","type":"publication"},{"authors":["Haiping Lu","Xudong Jiang","Wei-Yun Yau"],"categories":[],"content":"","date":1038700800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785773,"objectID":"d8bbe5fc2c9a6af2bc9173a0fc96fa4f","permalink":"https://haipinglu.github.io/publication/lu-2002-effective/","publishdate":"2021-12-29T13:49:32.23873Z","relpermalink":"/publication/lu-2002-effective/","section":"publication","summary":"Minutiae extraction is a crucial step in an automatic fingerprint identification system. However, the presence of noise in poor-quality images causes a large number of extraction errors, including the dropping of true minutiae and production of false minutiae. A study on these errors reveals that postprocessing is effective in removing false minutiae while keeping true ones. Furthermore, the overall processing efficiency could be improved because of the reduction in total minutia number. In this paper, we present a novel fingerprint image postprocessing algorithm. It is developed based on several rules, which are generalized through a study on the errors that commonly occur in minutiae extraction and their effects on the overall verification performance. Thorough experimental tests demonstrate the proposed postprocessing algorithm to be both effective and efficient.","tags":[],"title":"Effective and efficient fingerprint image postprocessing","type":"publication"},{"authors":["Haiping Lu","Xuxia Shi","Yun Q Shi","Alex C Kot","Lihui Chen"],"categories":[],"content":"","date":1038700800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785763,"objectID":"fdd5c2530dbc38cdb0a87024c5872b4e","permalink":"https://haipinglu.github.io/publication/lu-2002-watermark/","publishdate":"2021-12-29T13:49:22.902468Z","relpermalink":"/publication/lu-2002-watermark/","section":"publication","summary":"This paper investigates the feasibility of watermark embedding in the discrete cosine transform (DCT) domain for binary images. Watermark embedding is known to be difficult for binary images due to their binary nature. For frequency domain approach to binary image watermarking, a post-embedding binarization is a necessary step to ensure that the watermarked image is still a binary image. This step disturbs the watermark embedded and is likely to remove the watermark. We have succeeded in combating this interference by embedding watermarks in the DC components of DCT and employing a biased binarization threshold. This algorithm can be applied to binary images in general and experiments show that the embedding algorithm proposed can not only survive binarization, but also provide some degree of robustness against common image processing.","tags":[],"title":"Watermark embedding in DC components of DCT for binary images","type":"publication"},{"authors":["Haiping Lu","Jian Wang","Alex C Kot","Yun Q Shi"],"categories":[],"content":"","date":102816e4,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640785768,"objectID":"ca7180400d092580848f98317daae9c3","permalink":"https://haipinglu.github.io/publication/lu-2002-objective/","publishdate":"2021-12-29T13:49:27.096314Z","relpermalink":"/publication/lu-2002-objective/","section":"publication","summary":"As we are moving to a digital world, digital document image processing is receiving more and more attention. Digital document images are essentially binary images. In applications related to binary document images, such as data hiding and watermarking in binary images, distortion may be present and it is necessary to measure the distortion for performance comparison. However traditional objective distortion measures cannot describe the distortion in binary images well to have a good match with human visual perception. In this paper we present a novel objective distortion measure for binary document images that well correlates to the subjective distortion perception. This measure is based on the reciprocal of distance that is straight forward to calculate. Our results show that the proposed distortion measure matches well with subjective evaluation found on human visual perception.","tags":[],"title":"An objective distortion measure for binary document images based on human visual perception","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://haipinglu.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]